{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Gabriele_Di_Lieto_874143_assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH5ja_uiJbr6"
      },
      "source": [
        "# CNN for MNIST digits dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVxosTe6H1d0"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBGLR4_BhMsR"
      },
      "source": [
        "Importing the libraries we need to build the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YprDUMHtJOi-"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1SesUxlNmmx"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRCZtJ7JOjF"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBUoaKTbkNch"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQLKYH4Yi6RD"
      },
      "source": [
        "## Declaring functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1FGz9zJi_bt"
      },
      "source": [
        "def plt_classes_histogram(y, nb_classes):\n",
        "  plt.hist(y, bins = np.linspace(min(set(y)), max(set(y))+1, num=nb_classes+1))\n",
        "  plt.show()"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XYTKIGST_Sh"
      },
      "source": [
        "def plot_history(x_plot, network_history, best_epoch=None):\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.ylim(0.0,0.9)\n",
        "    plt.plot(x_plot, network_history.history['loss'])\n",
        "    plt.plot(x_plot, network_history.history['val_loss'])\n",
        "    if best_epoch != None:\n",
        "      plt.plot(best_epoch, network_history.history['val_loss'][best_epoch], marker='o')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.plot(x_plot, network_history.history['accuracy'])\n",
        "    plt.plot(x_plot, network_history.history['val_accuracy'])\n",
        "    if best_epoch != None:\n",
        "      plt.plot(best_epoch, network_history.history['val_accuracy'][best_epoch], marker='o')\n",
        "    plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "    plt.show()"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYoKgMkTIaUd"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7YdadPyI8BF"
      },
      "source": [
        "Loading the train and test sets of MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD1gz2K2IgPV"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0VtmMfDPL8p"
      },
      "source": [
        "##Inspecting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "opSUc_NvIC9o",
        "outputId": "402e1eb9-9d3e-45ed-f5d3-f855cb017739"
      },
      "source": [
        "print(\"x_train shape: \", x_train.shape)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape:  (60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qUEAQU5XIdMB",
        "outputId": "77add151-64f4-44cd-abad-ee173122c6f4"
      },
      "source": [
        "nb_classes = len(set(y_train))\n",
        "print('Number of categories:',nb_classes)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of categories: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nLzCeZAIIdMC",
        "outputId": "9b78c2fd-88da-45e1-e439-4c82707660d3"
      },
      "source": [
        "x_train[0].shape, x_train[0].shape[0]*x_train[0].shape[1], np.min(x_train[0]), np.max(x_train[0])"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((28, 28), 784, 0, 255)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "YlBob9AWEP6u",
        "outputId": "f0af03aa-88b3-49ce-9d3b-0c4b6f273c4f"
      },
      "source": [
        "plt.imshow(x_train[0])"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb408b06550>"
            ]
          },
          "metadata": {},
          "execution_count": 144
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49AyGv8avzMP"
      },
      "source": [
        "As we can see below, the dataset is quite balanced, and the distributions of train and test dataset are similiar. We won't go for a rebalancing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "O93j0d7xGsBj",
        "outputId": "4e67090a-9922-43e1-bfde-874db3f0108c"
      },
      "source": [
        "print(dict(Counter(y_train)))\n",
        "print(dict(Counter(y_test)))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{5: 5421, 0: 5923, 4: 5842, 1: 6742, 9: 5949, 2: 5958, 3: 6131, 6: 5918, 7: 6265, 8: 5851}\n",
            "{7: 1028, 2: 1032, 1: 1135, 0: 980, 4: 982, 9: 1009, 5: 892, 6: 958, 3: 1010, 8: 974}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "TJvyKG3zZeOW",
        "outputId": "410cedde-f2c1-40ac-e822-f4fb3f430282"
      },
      "source": [
        "plt_classes_histogram(y_train, nb_classes)\n",
        "plt_classes_histogram(y_test, nb_classes)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjWrQr5vWTTG"
      },
      "source": [
        "## Preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbqPsS06TnuJ"
      },
      "source": [
        "seed = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiV-ANBJKqKE"
      },
      "source": [
        "### Data normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80szZd-gM8yM"
      },
      "source": [
        "Here we perform a normalization of the data, casting images to matrix of float between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOS0DWXOROSF"
      },
      "source": [
        "X_train = x_train.astype(\"float32\")/255\n",
        "X_test = x_test.astype(\"float32\")/255"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvUI192ak_TR"
      },
      "source": [
        "### Reshaping the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thwVdk26lEtN"
      },
      "source": [
        "Below we transform the shape of the dataset to 28x28x1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFnC3ZZNlJrl"
      },
      "source": [
        "X_train = np.expand_dims(X_train, -1)\n",
        "X_test = np.expand_dims(X_test, -1)\n",
        "input_shape = (28,28,1)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_now7mKBmb3f",
        "outputId": "5e438c95-952f-445d-928d-b9c6eee70c97"
      },
      "source": [
        "print(\"x_train after reshape: \", X_train.shape)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train after reshape:  (60000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D26w_WQWJVQu"
      },
      "source": [
        "### Shuffle data and check good train/validation splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAw03P5vJuNj"
      },
      "source": [
        "Here we shuffle the data before splitting to avoid imbalances between the training and validation set distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kmCCE_eKcZx"
      },
      "source": [
        "Y_train = shuffle(y_train, random_state = seed)\n",
        "X_train = shuffle(X_train, random_state = seed)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_fCwONCALhz"
      },
      "source": [
        "### Split Training and Validation Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaUv00KqMtyN"
      },
      "source": [
        "Since the dataset is quite populous and to reduce the differences between the training distribution and the validation distribution, we consider a validation set of 10%.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxe5WJdoALh1"
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sz3Jct-SALiA",
        "outputId": "0e417dc6-607e-4250-91cf-38bb341bef17"
      },
      "source": [
        "print('Size of the training set:', X_train.shape)\n",
        "print('Size of the validation set:', X_val.shape)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the training set: (54000, 28, 28, 1)\n",
            "Size of the validation set: (6000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "D-6cnQg1W64O",
        "outputId": "38036aa2-63c5-44b4-e674-a814503e6909"
      },
      "source": [
        "plt_classes_histogram(Y_train, nb_classes)\n",
        "plt_classes_histogram(Y_val, nb_classes)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NR0R2acXmMA"
      },
      "source": [
        "As we can see after the splitting both the training and the validation distributions are quite similiar. So 10% seems a good choice for a validation splitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vAzeomqU8EG"
      },
      "source": [
        "### Categorization of the classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GeCi5_9ALhv"
      },
      "source": [
        "Y_train =  keras.utils.to_categorical(Y_train, nb_classes)\n",
        "Y_val =  keras.utils.to_categorical(Y_val, nb_classes)\n",
        "Y_test =  keras.utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "f0POBe6AmRg4",
        "outputId": "314fbd94-119b-4fc1-f4e2-a3e9ed46a040"
      },
      "source": [
        "print(\"y_train shape after casting to categorical : \", Y_train.shape)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape after casting to categorical :  (54000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb9aljYxJbsK"
      },
      "source": [
        "## Building the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6QsOtDno0s0"
      },
      "source": [
        "The network architecture consists of:\n",
        "1.   a convolutional layer, of 8 filters with 5x5 window\n",
        "2.   a max pooling layer, which reduces the output of the previous layer by a factor of 4\n",
        "3.   a convolutional layer, of 16 filters with 3x3 window\n",
        "4.   a max pooling layer, which reduces the output of the previous layer by a factor of 4\n",
        "5.   a flatten layer, which converts the output shape of the previous layer into a flat layer, with a dropout rate of 0.3 as a regularization technique\n",
        "6.   an output layer with 10 neurons totally connected to the previous layer\n",
        "\n",
        "We have that the number of parameters for the first convolutional layer **(1)** is *((5x5)+1)x8 = 208*, as we have windows of 5x5 weights for 8 filters plus the bias parameter for the 8 filters. \n",
        "\n",
        "The output of this layer has a shape *(28-5+1)x(28-5+1)x8*, which is reduced by a factor of 4 by the max pooling layer **(2)**, becoming *13x13x8*.\n",
        "\n",
        "Then we have that the number of parameters for the second convolutional layer **(3)** is *(((3x3)x8)+1)x16 = 1168*, as we have windows of 3x3 weights for 8 channels for 16 filters plus the bias parameter for the 16 filters.\n",
        "\n",
        "The output of this layer has a shape *(13-3+1)x(13-3+1)x16*, which is reduced by a factor of 4 by the max pooling layer **(4)**, becoming *5x5x16*.\n",
        "\n",
        "Then the flatten layer **(5)** transforms the previous *5x5x16* shape into a flat layer of *400* neurons, that is fully connected to the output layer of 10 neurons **(6)**. So the number of parameters to link those layers is *(400+1)x10 = 4010*.\n",
        "\n",
        "The total number of parameters of the networks is then *208+1168+4010 = 5386*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcqcBYi5Ggid"
      },
      "source": [
        "![CNN-MINST-6k.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aLoidf7rRBX"
      },
      "source": [
        "### CNN Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfJg6PqUGfh2"
      },
      "source": [
        "Here is a list of the hyper-parameters used to tune the network:\n",
        "*   optimizer: adam\n",
        "*   activation function: relu \n",
        "*   output function: softmax \n",
        "*   learning rate: 0.001\n",
        "*   batch size: 128\n",
        "*   number of epochs: 200 (using model checkpoint to store the weights of the best epoch with lowest loss)\n",
        "*   dropout rate: 30%\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8giPmXK24yL"
      },
      "source": [
        "initializer = tf.keras.initializers.GlorotUniform(seed=seed) "
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "605Q6l1yrRBX"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "     keras.Input(shape=input_shape),\n",
        "     layers.Conv2D(8, kernel_size=(5, 5), activation=\"relu\", kernel_initializer=initializer),\n",
        "     layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "     layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\", kernel_initializer=initializer),\n",
        "     layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "     layers.Flatten(),\n",
        "     layers.Dropout(0.3),\n",
        "     layers.Dense(nb_classes, activation=\"softmax\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8YqwQLwWrRBY",
        "outputId": "3abbf340-2991-40d3-bc85-67aebe08ba18"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 24, 24, 8)         208       \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 12, 12, 8)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 10, 10, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 400)               0         \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 400)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                4010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,386\n",
            "Trainable params: 5,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mGrNqDiPrRBY",
        "scrolled": false,
        "outputId": "84860bdb-12aa-4195-9bfb-7a7e57fd064b"
      },
      "source": [
        "n_epochs = 200\n",
        "batch_size = 128\n",
        "\n",
        "best_model = ModelCheckpoint('best_model.h5', verbose=1, save_best_only=True)\n",
        "\n",
        "network_history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=n_epochs, verbose=2, validation_data=(X_val, Y_val), callbacks=[best_model])"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.16668, saving model to best_model.h5\n",
            "422/422 - 3s - loss: 0.5624 - accuracy: 0.8240 - val_loss: 0.1667 - val_accuracy: 0.9502 - 3s/epoch - 8ms/step\n",
            "Epoch 2/200\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.16668 to 0.10981, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.1742 - accuracy: 0.9468 - val_loss: 0.1098 - val_accuracy: 0.9665 - 2s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.10981 to 0.08706, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.1284 - accuracy: 0.9616 - val_loss: 0.0871 - val_accuracy: 0.9717 - 2s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.08706 to 0.07368, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.1067 - accuracy: 0.9669 - val_loss: 0.0737 - val_accuracy: 0.9773 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.07368 to 0.06996, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0960 - accuracy: 0.9710 - val_loss: 0.0700 - val_accuracy: 0.9783 - 2s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.06996 to 0.05832, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0882 - accuracy: 0.9730 - val_loss: 0.0583 - val_accuracy: 0.9817 - 2s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.05832 to 0.05507, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0820 - accuracy: 0.9744 - val_loss: 0.0551 - val_accuracy: 0.9842 - 2s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.05507 to 0.05478, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0758 - accuracy: 0.9764 - val_loss: 0.0548 - val_accuracy: 0.9828 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.05478 to 0.05278, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0705 - accuracy: 0.9778 - val_loss: 0.0528 - val_accuracy: 0.9840 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.05278 to 0.04830, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0677 - accuracy: 0.9788 - val_loss: 0.0483 - val_accuracy: 0.9860 - 2s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.04830 to 0.04816, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0659 - accuracy: 0.9793 - val_loss: 0.0482 - val_accuracy: 0.9860 - 2s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.04816 to 0.04587, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0642 - accuracy: 0.9799 - val_loss: 0.0459 - val_accuracy: 0.9875 - 2s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.04587 to 0.04566, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0622 - accuracy: 0.9803 - val_loss: 0.0457 - val_accuracy: 0.9850 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.04566 to 0.04440, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0586 - accuracy: 0.9816 - val_loss: 0.0444 - val_accuracy: 0.9867 - 2s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.04440 to 0.04296, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0575 - accuracy: 0.9822 - val_loss: 0.0430 - val_accuracy: 0.9867 - 2s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.04296\n",
            "422/422 - 2s - loss: 0.0542 - accuracy: 0.9831 - val_loss: 0.0431 - val_accuracy: 0.9885 - 2s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.04296 to 0.04219, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0557 - accuracy: 0.9826 - val_loss: 0.0422 - val_accuracy: 0.9873 - 2s/epoch - 5ms/step\n",
            "Epoch 18/200\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.04219\n",
            "422/422 - 2s - loss: 0.0529 - accuracy: 0.9832 - val_loss: 0.0436 - val_accuracy: 0.9877 - 2s/epoch - 5ms/step\n",
            "Epoch 19/200\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.04219 to 0.03996, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0511 - accuracy: 0.9836 - val_loss: 0.0400 - val_accuracy: 0.9890 - 2s/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.03996\n",
            "422/422 - 2s - loss: 0.0526 - accuracy: 0.9836 - val_loss: 0.0407 - val_accuracy: 0.9887 - 2s/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.03996 to 0.03776, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0499 - accuracy: 0.9845 - val_loss: 0.0378 - val_accuracy: 0.9898 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.03776\n",
            "422/422 - 2s - loss: 0.0492 - accuracy: 0.9847 - val_loss: 0.0380 - val_accuracy: 0.9893 - 2s/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.03776\n",
            "422/422 - 2s - loss: 0.0490 - accuracy: 0.9844 - val_loss: 0.0392 - val_accuracy: 0.9893 - 2s/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.03776\n",
            "422/422 - 2s - loss: 0.0457 - accuracy: 0.9852 - val_loss: 0.0407 - val_accuracy: 0.9880 - 2s/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.03776\n",
            "422/422 - 2s - loss: 0.0459 - accuracy: 0.9853 - val_loss: 0.0382 - val_accuracy: 0.9898 - 2s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.03776 to 0.03744, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0469 - accuracy: 0.9847 - val_loss: 0.0374 - val_accuracy: 0.9902 - 2s/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.03744\n",
            "422/422 - 2s - loss: 0.0446 - accuracy: 0.9859 - val_loss: 0.0375 - val_accuracy: 0.9900 - 2s/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.03744 to 0.03496, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0456 - accuracy: 0.9852 - val_loss: 0.0350 - val_accuracy: 0.9905 - 2s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.03496\n",
            "422/422 - 2s - loss: 0.0425 - accuracy: 0.9866 - val_loss: 0.0378 - val_accuracy: 0.9892 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.03496\n",
            "422/422 - 2s - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.0386 - val_accuracy: 0.9900 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.03496\n",
            "422/422 - 2s - loss: 0.0427 - accuracy: 0.9861 - val_loss: 0.0356 - val_accuracy: 0.9902 - 2s/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.03496\n",
            "422/422 - 2s - loss: 0.0418 - accuracy: 0.9866 - val_loss: 0.0370 - val_accuracy: 0.9900 - 2s/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.03496\n",
            "422/422 - 2s - loss: 0.0402 - accuracy: 0.9868 - val_loss: 0.0352 - val_accuracy: 0.9905 - 2s/epoch - 5ms/step\n",
            "Epoch 34/200\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.03496 to 0.03449, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0417 - accuracy: 0.9864 - val_loss: 0.0345 - val_accuracy: 0.9907 - 2s/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.03449\n",
            "422/422 - 2s - loss: 0.0406 - accuracy: 0.9873 - val_loss: 0.0353 - val_accuracy: 0.9900 - 2s/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.03449 to 0.03423, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0407 - accuracy: 0.9870 - val_loss: 0.0342 - val_accuracy: 0.9903 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.03423\n",
            "422/422 - 2s - loss: 0.0413 - accuracy: 0.9865 - val_loss: 0.0346 - val_accuracy: 0.9908 - 2s/epoch - 5ms/step\n",
            "Epoch 38/200\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.03423\n",
            "422/422 - 2s - loss: 0.0403 - accuracy: 0.9874 - val_loss: 0.0350 - val_accuracy: 0.9900 - 2s/epoch - 5ms/step\n",
            "Epoch 39/200\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.03423\n",
            "422/422 - 2s - loss: 0.0389 - accuracy: 0.9873 - val_loss: 0.0347 - val_accuracy: 0.9900 - 2s/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.03423 to 0.03250, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0381 - accuracy: 0.9876 - val_loss: 0.0325 - val_accuracy: 0.9907 - 2s/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.03250\n",
            "422/422 - 2s - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0333 - val_accuracy: 0.9907 - 2s/epoch - 5ms/step\n",
            "Epoch 42/200\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.03250\n",
            "422/422 - 2s - loss: 0.0392 - accuracy: 0.9872 - val_loss: 0.0325 - val_accuracy: 0.9915 - 2s/epoch - 5ms/step\n",
            "Epoch 43/200\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.03250\n",
            "422/422 - 2s - loss: 0.0366 - accuracy: 0.9884 - val_loss: 0.0349 - val_accuracy: 0.9905 - 2s/epoch - 5ms/step\n",
            "Epoch 44/200\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.03250\n",
            "422/422 - 2s - loss: 0.0355 - accuracy: 0.9879 - val_loss: 0.0345 - val_accuracy: 0.9903 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.03250\n",
            "422/422 - 2s - loss: 0.0374 - accuracy: 0.9878 - val_loss: 0.0337 - val_accuracy: 0.9912 - 2s/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.03250\n",
            "422/422 - 2s - loss: 0.0357 - accuracy: 0.9891 - val_loss: 0.0327 - val_accuracy: 0.9912 - 2s/epoch - 5ms/step\n",
            "Epoch 47/200\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.03250\n",
            "422/422 - 2s - loss: 0.0372 - accuracy: 0.9884 - val_loss: 0.0329 - val_accuracy: 0.9910 - 2s/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.03250\n",
            "422/422 - 2s - loss: 0.0355 - accuracy: 0.9885 - val_loss: 0.0327 - val_accuracy: 0.9913 - 2s/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.03250\n",
            "422/422 - 2s - loss: 0.0375 - accuracy: 0.9879 - val_loss: 0.0328 - val_accuracy: 0.9905 - 2s/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.03250\n",
            "422/422 - 2s - loss: 0.0364 - accuracy: 0.9879 - val_loss: 0.0357 - val_accuracy: 0.9910 - 2s/epoch - 5ms/step\n",
            "Epoch 51/200\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.03250 to 0.02906, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0355 - accuracy: 0.9881 - val_loss: 0.0291 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.0355 - val_accuracy: 0.9907 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0345 - accuracy: 0.9889 - val_loss: 0.0323 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0344 - accuracy: 0.9881 - val_loss: 0.0315 - val_accuracy: 0.9910 - 2s/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0328 - accuracy: 0.9893 - val_loss: 0.0318 - val_accuracy: 0.9913 - 2s/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0342 - accuracy: 0.9886 - val_loss: 0.0336 - val_accuracy: 0.9910 - 2s/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0348 - accuracy: 0.9884 - val_loss: 0.0323 - val_accuracy: 0.9912 - 2s/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0322 - accuracy: 0.9894 - val_loss: 0.0326 - val_accuracy: 0.9903 - 2s/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0347 - accuracy: 0.9891 - val_loss: 0.0307 - val_accuracy: 0.9913 - 2s/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0335 - accuracy: 0.9891 - val_loss: 0.0315 - val_accuracy: 0.9905 - 2s/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0337 - accuracy: 0.9889 - val_loss: 0.0320 - val_accuracy: 0.9908 - 2s/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0337 - accuracy: 0.9890 - val_loss: 0.0323 - val_accuracy: 0.9905 - 2s/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0337 - accuracy: 0.9888 - val_loss: 0.0311 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0310 - accuracy: 0.9899 - val_loss: 0.0313 - val_accuracy: 0.9910 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.0324 - val_accuracy: 0.9915 - 2s/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0329 - accuracy: 0.9891 - val_loss: 0.0298 - val_accuracy: 0.9920 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0314 - accuracy: 0.9899 - val_loss: 0.0307 - val_accuracy: 0.9912 - 2s/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0308 - accuracy: 0.9901 - val_loss: 0.0321 - val_accuracy: 0.9902 - 2s/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.02906\n",
            "422/422 - 2s - loss: 0.0325 - accuracy: 0.9889 - val_loss: 0.0317 - val_accuracy: 0.9907 - 2s/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.02906 to 0.02833, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0302 - accuracy: 0.9895 - val_loss: 0.0283 - val_accuracy: 0.9932 - 2s/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.02833\n",
            "422/422 - 2s - loss: 0.0316 - accuracy: 0.9892 - val_loss: 0.0298 - val_accuracy: 0.9923 - 2s/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.02833 to 0.02744, saving model to best_model.h5\n",
            "422/422 - 2s - loss: 0.0316 - accuracy: 0.9894 - val_loss: 0.0274 - val_accuracy: 0.9918 - 2s/epoch - 5ms/step\n",
            "Epoch 73/200\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0315 - accuracy: 0.9893 - val_loss: 0.0290 - val_accuracy: 0.9923 - 2s/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0301 - accuracy: 0.9900 - val_loss: 0.0308 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 75/200\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0310 - accuracy: 0.9892 - val_loss: 0.0323 - val_accuracy: 0.9915 - 2s/epoch - 5ms/step\n",
            "Epoch 76/200\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0294 - accuracy: 0.9899 - val_loss: 0.0297 - val_accuracy: 0.9910 - 2s/epoch - 5ms/step\n",
            "Epoch 77/200\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0319 - accuracy: 0.9899 - val_loss: 0.0304 - val_accuracy: 0.9915 - 2s/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0307 - accuracy: 0.9895 - val_loss: 0.0343 - val_accuracy: 0.9903 - 2s/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0309 - accuracy: 0.9898 - val_loss: 0.0325 - val_accuracy: 0.9913 - 2s/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.0356 - val_accuracy: 0.9898 - 2s/epoch - 5ms/step\n",
            "Epoch 81/200\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0299 - accuracy: 0.9898 - val_loss: 0.0330 - val_accuracy: 0.9913 - 2s/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.0360 - val_accuracy: 0.9903 - 2s/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0294 - accuracy: 0.9905 - val_loss: 0.0312 - val_accuracy: 0.9918 - 2s/epoch - 5ms/step\n",
            "Epoch 84/200\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0282 - accuracy: 0.9909 - val_loss: 0.0308 - val_accuracy: 0.9915 - 2s/epoch - 5ms/step\n",
            "Epoch 85/200\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.0304 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 86/200\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.0307 - val_accuracy: 0.9910 - 2s/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0293 - accuracy: 0.9901 - val_loss: 0.0315 - val_accuracy: 0.9915 - 2s/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0292 - accuracy: 0.9903 - val_loss: 0.0321 - val_accuracy: 0.9910 - 2s/epoch - 5ms/step\n",
            "Epoch 89/200\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0284 - accuracy: 0.9904 - val_loss: 0.0304 - val_accuracy: 0.9917 - 2s/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0289 - accuracy: 0.9907 - val_loss: 0.0294 - val_accuracy: 0.9922 - 2s/epoch - 5ms/step\n",
            "Epoch 91/200\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0273 - accuracy: 0.9909 - val_loss: 0.0308 - val_accuracy: 0.9922 - 2s/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0267 - accuracy: 0.9911 - val_loss: 0.0304 - val_accuracy: 0.9918 - 2s/epoch - 5ms/step\n",
            "Epoch 93/200\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0289 - accuracy: 0.9903 - val_loss: 0.0305 - val_accuracy: 0.9912 - 2s/epoch - 6ms/step\n",
            "Epoch 94/200\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0278 - accuracy: 0.9904 - val_loss: 0.0300 - val_accuracy: 0.9918 - 2s/epoch - 5ms/step\n",
            "Epoch 95/200\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0283 - accuracy: 0.9901 - val_loss: 0.0294 - val_accuracy: 0.9923 - 2s/epoch - 5ms/step\n",
            "Epoch 96/200\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0278 - accuracy: 0.9906 - val_loss: 0.0297 - val_accuracy: 0.9915 - 2s/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0267 - accuracy: 0.9911 - val_loss: 0.0314 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 98/200\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0262 - accuracy: 0.9910 - val_loss: 0.0316 - val_accuracy: 0.9908 - 2s/epoch - 5ms/step\n",
            "Epoch 99/200\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0286 - accuracy: 0.9910 - val_loss: 0.0313 - val_accuracy: 0.9922 - 2s/epoch - 5ms/step\n",
            "Epoch 100/200\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0271 - accuracy: 0.9905 - val_loss: 0.0321 - val_accuracy: 0.9915 - 2s/epoch - 5ms/step\n",
            "Epoch 101/200\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.0323 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 102/200\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.0316 - val_accuracy: 0.9920 - 2s/epoch - 5ms/step\n",
            "Epoch 103/200\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.0329 - val_accuracy: 0.9915 - 2s/epoch - 5ms/step\n",
            "Epoch 104/200\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0257 - accuracy: 0.9911 - val_loss: 0.0327 - val_accuracy: 0.9912 - 2s/epoch - 5ms/step\n",
            "Epoch 105/200\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0265 - accuracy: 0.9906 - val_loss: 0.0313 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 106/200\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0318 - val_accuracy: 0.9920 - 2s/epoch - 5ms/step\n",
            "Epoch 107/200\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0262 - accuracy: 0.9913 - val_loss: 0.0306 - val_accuracy: 0.9925 - 2s/epoch - 5ms/step\n",
            "Epoch 108/200\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0275 - accuracy: 0.9908 - val_loss: 0.0332 - val_accuracy: 0.9915 - 2s/epoch - 5ms/step\n",
            "Epoch 109/200\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0277 - accuracy: 0.9906 - val_loss: 0.0322 - val_accuracy: 0.9923 - 2s/epoch - 5ms/step\n",
            "Epoch 110/200\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0266 - accuracy: 0.9910 - val_loss: 0.0318 - val_accuracy: 0.9920 - 2s/epoch - 5ms/step\n",
            "Epoch 111/200\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.0349 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 112/200\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0255 - accuracy: 0.9918 - val_loss: 0.0322 - val_accuracy: 0.9910 - 2s/epoch - 6ms/step\n",
            "Epoch 113/200\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0266 - accuracy: 0.9909 - val_loss: 0.0307 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 114/200\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0258 - accuracy: 0.9916 - val_loss: 0.0316 - val_accuracy: 0.9922 - 2s/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.0310 - val_accuracy: 0.9925 - 2s/epoch - 5ms/step\n",
            "Epoch 116/200\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.0304 - val_accuracy: 0.9920 - 2s/epoch - 5ms/step\n",
            "Epoch 117/200\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.0321 - val_accuracy: 0.9918 - 2s/epoch - 5ms/step\n",
            "Epoch 118/200\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.0317 - val_accuracy: 0.9923 - 2s/epoch - 5ms/step\n",
            "Epoch 119/200\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.0328 - val_accuracy: 0.9918 - 2s/epoch - 5ms/step\n",
            "Epoch 120/200\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0267 - accuracy: 0.9911 - val_loss: 0.0327 - val_accuracy: 0.9915 - 2s/epoch - 5ms/step\n",
            "Epoch 121/200\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0253 - accuracy: 0.9917 - val_loss: 0.0325 - val_accuracy: 0.9923 - 2s/epoch - 6ms/step\n",
            "Epoch 122/200\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.0328 - val_accuracy: 0.9920 - 2s/epoch - 5ms/step\n",
            "Epoch 123/200\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0257 - accuracy: 0.9918 - val_loss: 0.0314 - val_accuracy: 0.9927 - 2s/epoch - 5ms/step\n",
            "Epoch 124/200\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.0322 - val_accuracy: 0.9922 - 2s/epoch - 5ms/step\n",
            "Epoch 125/200\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.0328 - val_accuracy: 0.9923 - 2s/epoch - 5ms/step\n",
            "Epoch 126/200\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0262 - accuracy: 0.9910 - val_loss: 0.0325 - val_accuracy: 0.9918 - 2s/epoch - 5ms/step\n",
            "Epoch 127/200\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.0330 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 128/200\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0262 - accuracy: 0.9914 - val_loss: 0.0330 - val_accuracy: 0.9922 - 2s/epoch - 5ms/step\n",
            "Epoch 129/200\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.0338 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 130/200\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0241 - accuracy: 0.9915 - val_loss: 0.0334 - val_accuracy: 0.9927 - 2s/epoch - 5ms/step\n",
            "Epoch 131/200\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.0326 - val_accuracy: 0.9928 - 2s/epoch - 5ms/step\n",
            "Epoch 132/200\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.0306 - val_accuracy: 0.9923 - 2s/epoch - 5ms/step\n",
            "Epoch 133/200\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0346 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 134/200\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0248 - accuracy: 0.9916 - val_loss: 0.0330 - val_accuracy: 0.9915 - 2s/epoch - 5ms/step\n",
            "Epoch 135/200\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.0304 - val_accuracy: 0.9930 - 2s/epoch - 5ms/step\n",
            "Epoch 136/200\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0240 - accuracy: 0.9919 - val_loss: 0.0321 - val_accuracy: 0.9918 - 2s/epoch - 5ms/step\n",
            "Epoch 137/200\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0239 - accuracy: 0.9922 - val_loss: 0.0327 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 138/200\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.0321 - val_accuracy: 0.9927 - 2s/epoch - 5ms/step\n",
            "Epoch 139/200\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.0305 - val_accuracy: 0.9927 - 2s/epoch - 5ms/step\n",
            "Epoch 140/200\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0315 - val_accuracy: 0.9918 - 2s/epoch - 5ms/step\n",
            "Epoch 141/200\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0311 - val_accuracy: 0.9925 - 2s/epoch - 5ms/step\n",
            "Epoch 142/200\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.0328 - val_accuracy: 0.9910 - 2s/epoch - 5ms/step\n",
            "Epoch 143/200\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.0347 - val_accuracy: 0.9928 - 2s/epoch - 5ms/step\n",
            "Epoch 144/200\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.0330 - val_accuracy: 0.9920 - 2s/epoch - 5ms/step\n",
            "Epoch 145/200\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0235 - accuracy: 0.9915 - val_loss: 0.0321 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 146/200\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0238 - accuracy: 0.9919 - val_loss: 0.0331 - val_accuracy: 0.9925 - 2s/epoch - 5ms/step\n",
            "Epoch 147/200\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.0308 - val_accuracy: 0.9925 - 2s/epoch - 5ms/step\n",
            "Epoch 148/200\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.0314 - val_accuracy: 0.9918 - 2s/epoch - 5ms/step\n",
            "Epoch 149/200\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0223 - accuracy: 0.9917 - val_loss: 0.0304 - val_accuracy: 0.9932 - 2s/epoch - 5ms/step\n",
            "Epoch 150/200\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.0306 - val_accuracy: 0.9928 - 2s/epoch - 5ms/step\n",
            "Epoch 151/200\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0243 - accuracy: 0.9924 - val_loss: 0.0307 - val_accuracy: 0.9925 - 2s/epoch - 5ms/step\n",
            "Epoch 152/200\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0246 - accuracy: 0.9914 - val_loss: 0.0335 - val_accuracy: 0.9912 - 2s/epoch - 5ms/step\n",
            "Epoch 153/200\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0305 - val_accuracy: 0.9920 - 2s/epoch - 5ms/step\n",
            "Epoch 154/200\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.0319 - val_accuracy: 0.9923 - 2s/epoch - 5ms/step\n",
            "Epoch 155/200\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.0339 - val_accuracy: 0.9925 - 2s/epoch - 5ms/step\n",
            "Epoch 156/200\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0240 - accuracy: 0.9922 - val_loss: 0.0322 - val_accuracy: 0.9928 - 2s/epoch - 5ms/step\n",
            "Epoch 157/200\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.0323 - val_accuracy: 0.9922 - 2s/epoch - 6ms/step\n",
            "Epoch 158/200\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0228 - accuracy: 0.9923 - val_loss: 0.0325 - val_accuracy: 0.9920 - 2s/epoch - 5ms/step\n",
            "Epoch 159/200\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.0332 - val_accuracy: 0.9912 - 2s/epoch - 5ms/step\n",
            "Epoch 160/200\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0229 - accuracy: 0.9922 - val_loss: 0.0323 - val_accuracy: 0.9922 - 2s/epoch - 5ms/step\n",
            "Epoch 161/200\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0220 - accuracy: 0.9928 - val_loss: 0.0305 - val_accuracy: 0.9923 - 2s/epoch - 5ms/step\n",
            "Epoch 162/200\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.0310 - val_accuracy: 0.9925 - 2s/epoch - 5ms/step\n",
            "Epoch 163/200\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.0332 - val_accuracy: 0.9918 - 2s/epoch - 5ms/step\n",
            "Epoch 164/200\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0226 - accuracy: 0.9925 - val_loss: 0.0297 - val_accuracy: 0.9927 - 2s/epoch - 5ms/step\n",
            "Epoch 165/200\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0212 - accuracy: 0.9930 - val_loss: 0.0307 - val_accuracy: 0.9922 - 2s/epoch - 5ms/step\n",
            "Epoch 166/200\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.0303 - val_accuracy: 0.9928 - 2s/epoch - 5ms/step\n",
            "Epoch 167/200\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.0305 - val_accuracy: 0.9927 - 2s/epoch - 5ms/step\n",
            "Epoch 168/200\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0217 - accuracy: 0.9924 - val_loss: 0.0344 - val_accuracy: 0.9918 - 2s/epoch - 5ms/step\n",
            "Epoch 169/200\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.0305 - val_accuracy: 0.9922 - 2s/epoch - 5ms/step\n",
            "Epoch 170/200\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.0315 - val_accuracy: 0.9927 - 2s/epoch - 5ms/step\n",
            "Epoch 171/200\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.0301 - val_accuracy: 0.9922 - 2s/epoch - 5ms/step\n",
            "Epoch 172/200\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0215 - accuracy: 0.9921 - val_loss: 0.0310 - val_accuracy: 0.9925 - 2s/epoch - 5ms/step\n",
            "Epoch 173/200\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0227 - accuracy: 0.9923 - val_loss: 0.0320 - val_accuracy: 0.9927 - 2s/epoch - 5ms/step\n",
            "Epoch 174/200\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0226 - accuracy: 0.9924 - val_loss: 0.0314 - val_accuracy: 0.9925 - 2s/epoch - 5ms/step\n",
            "Epoch 175/200\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0219 - accuracy: 0.9922 - val_loss: 0.0325 - val_accuracy: 0.9923 - 2s/epoch - 5ms/step\n",
            "Epoch 176/200\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.0330 - val_accuracy: 0.9922 - 2s/epoch - 5ms/step\n",
            "Epoch 177/200\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.0329 - val_accuracy: 0.9908 - 2s/epoch - 5ms/step\n",
            "Epoch 178/200\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.0337 - val_accuracy: 0.9918 - 2s/epoch - 5ms/step\n",
            "Epoch 179/200\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.0324 - val_accuracy: 0.9927 - 2s/epoch - 5ms/step\n",
            "Epoch 180/200\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0222 - accuracy: 0.9923 - val_loss: 0.0322 - val_accuracy: 0.9927 - 2s/epoch - 5ms/step\n",
            "Epoch 181/200\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.0335 - val_accuracy: 0.9922 - 2s/epoch - 5ms/step\n",
            "Epoch 182/200\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0226 - accuracy: 0.9919 - val_loss: 0.0323 - val_accuracy: 0.9925 - 2s/epoch - 5ms/step\n",
            "Epoch 183/200\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.0334 - val_accuracy: 0.9918 - 2s/epoch - 5ms/step\n",
            "Epoch 184/200\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.0331 - val_accuracy: 0.9925 - 2s/epoch - 5ms/step\n",
            "Epoch 185/200\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.0325 - val_accuracy: 0.9928 - 2s/epoch - 5ms/step\n",
            "Epoch 186/200\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.0319 - val_accuracy: 0.9923 - 2s/epoch - 5ms/step\n",
            "Epoch 187/200\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.0341 - val_accuracy: 0.9908 - 2s/epoch - 5ms/step\n",
            "Epoch 188/200\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0220 - accuracy: 0.9928 - val_loss: 0.0331 - val_accuracy: 0.9920 - 2s/epoch - 5ms/step\n",
            "Epoch 189/200\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0229 - accuracy: 0.9922 - val_loss: 0.0337 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 190/200\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0223 - accuracy: 0.9925 - val_loss: 0.0326 - val_accuracy: 0.9920 - 2s/epoch - 5ms/step\n",
            "Epoch 191/200\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.0340 - val_accuracy: 0.9923 - 2s/epoch - 5ms/step\n",
            "Epoch 192/200\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.0359 - val_accuracy: 0.9908 - 2s/epoch - 5ms/step\n",
            "Epoch 193/200\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.0358 - val_accuracy: 0.9915 - 2s/epoch - 5ms/step\n",
            "Epoch 194/200\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.0332 - val_accuracy: 0.9912 - 2s/epoch - 5ms/step\n",
            "Epoch 195/200\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.0320 - val_accuracy: 0.9927 - 2s/epoch - 5ms/step\n",
            "Epoch 196/200\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0304 - val_accuracy: 0.9917 - 2s/epoch - 5ms/step\n",
            "Epoch 197/200\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.0320 - val_accuracy: 0.9923 - 2s/epoch - 5ms/step\n",
            "Epoch 198/200\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.0310 - val_accuracy: 0.9930 - 2s/epoch - 5ms/step\n",
            "Epoch 199/200\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0226 - accuracy: 0.9922 - val_loss: 0.0325 - val_accuracy: 0.9920 - 2s/epoch - 5ms/step\n",
            "Epoch 200/200\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.02744\n",
            "422/422 - 2s - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.0312 - val_accuracy: 0.9915 - 2s/epoch - 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w7UIdtIWuCD"
      },
      "source": [
        "## Analyze and comment the training results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZqzVAbyhzqQ"
      },
      "source": [
        "### Plotting accuracy/loss graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSd4WeNr9Lzi"
      },
      "source": [
        "best_epoch = 72"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SQ66TvygbRRB",
        "outputId": "d2ecdf09-2a3f-47a5-a925-fd0b5d2118f2"
      },
      "source": [
        "print('history dict:', network_history.history)"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "history dict: {'loss': [0.5624433755874634, 0.17420890927314758, 0.1283891648054123, 0.10666550695896149, 0.09602024406194687, 0.08816683292388916, 0.08203800767660141, 0.07576458156108856, 0.07048496603965759, 0.06769175082445145, 0.06591309607028961, 0.06417600065469742, 0.06224632263183594, 0.0585843063890934, 0.0574546754360199, 0.05421997234225273, 0.055741146206855774, 0.05285729840397835, 0.051127638667821884, 0.05255194380879402, 0.049939315766096115, 0.049200937151908875, 0.04895491525530815, 0.04573788493871689, 0.045929525047540665, 0.046874288469552994, 0.04464131221175194, 0.045613180845975876, 0.04247106611728668, 0.04395100474357605, 0.04271107167005539, 0.04184336960315704, 0.04015909507870674, 0.04171141982078552, 0.040625546127557755, 0.04069888964295387, 0.041284870356321335, 0.04033636301755905, 0.03885393217206001, 0.038086578249931335, 0.03931776434183121, 0.039159033447504044, 0.03657575696706772, 0.03550424054265022, 0.03736705332994461, 0.035668738186359406, 0.03718166798353195, 0.03549304977059364, 0.037493832409381866, 0.03644154965877533, 0.03548469394445419, 0.0359053909778595, 0.034500852227211, 0.034385282546281815, 0.03284480422735214, 0.03415307402610779, 0.03482440486550331, 0.032184820622205734, 0.03474884852766991, 0.03350643441081047, 0.03373647853732109, 0.03370672091841698, 0.03369775414466858, 0.03099721297621727, 0.031158016994595528, 0.03285842016339302, 0.03142661601305008, 0.030792299658060074, 0.032492443919181824, 0.030201956629753113, 0.0316036157310009, 0.03156638145446777, 0.031516801565885544, 0.03006557933986187, 0.03102128766477108, 0.02936575375497341, 0.031900301575660706, 0.030694806948304176, 0.03092779777944088, 0.029893305152654648, 0.029865864664316177, 0.029922254383563995, 0.02942696399986744, 0.02820737287402153, 0.030417578294873238, 0.029437081888318062, 0.02928009256720543, 0.029171094298362732, 0.028440671041607857, 0.028914395719766617, 0.027262480929493904, 0.026651863008737564, 0.028850743547081947, 0.027811627835035324, 0.028253044933080673, 0.02779800072312355, 0.026695815846323967, 0.026188300922513008, 0.028618982061743736, 0.027072623372077942, 0.02561430260539055, 0.026512498036026955, 0.026337070390582085, 0.025741644203662872, 0.026545103639364243, 0.028047718107700348, 0.026211382821202278, 0.0275120846927166, 0.027715707197785378, 0.026633188128471375, 0.025281520560383797, 0.025500867515802383, 0.026609815657138824, 0.025813275948166847, 0.025301581248641014, 0.026543982326984406, 0.025717362761497498, 0.025723200291395187, 0.026487044990062714, 0.026661263778805733, 0.02528645470738411, 0.02565702609717846, 0.02573464810848236, 0.025256434455513954, 0.02616523951292038, 0.02617214247584343, 0.02534569427371025, 0.02623746357858181, 0.024212537333369255, 0.02409619651734829, 0.025169460102915764, 0.02417939156293869, 0.024455882608890533, 0.024798354133963585, 0.02524462155997753, 0.023971963673830032, 0.023925868794322014, 0.02488706074655056, 0.024525824934244156, 0.024010928347706795, 0.024549128487706184, 0.023048125207424164, 0.02469213493168354, 0.02389341965317726, 0.02346162684261799, 0.023826194927096367, 0.023771772161126137, 0.02443675696849823, 0.02230655774474144, 0.022696299478411674, 0.02430988848209381, 0.024575134739279747, 0.024382689967751503, 0.02200697548687458, 0.02411855012178421, 0.024022774770855904, 0.021693255752325058, 0.02278427965939045, 0.022581078112125397, 0.022931396961212158, 0.02200905978679657, 0.023489294573664665, 0.023451490327715874, 0.02264133282005787, 0.021167445927858353, 0.02353265881538391, 0.022590024396777153, 0.021677376702427864, 0.02353501319885254, 0.02254304103553295, 0.022150089964270592, 0.02148149348795414, 0.02266482636332512, 0.02263362891972065, 0.021900100633502007, 0.023604435846209526, 0.021453920751810074, 0.022577734664082527, 0.024509279057383537, 0.022173654288053513, 0.02159738540649414, 0.02262165956199169, 0.02348063513636589, 0.021872660145163536, 0.023146415129303932, 0.022016221657395363, 0.0215153768658638, 0.022010773420333862, 0.022893233224749565, 0.022335488349199295, 0.02232375554740429, 0.02207140065729618, 0.021705524995923042, 0.020982962101697922, 0.023098431527614594, 0.02108275517821312, 0.02170589566230774, 0.02148793451488018, 0.02261950448155403, 0.02209179289638996], 'accuracy': [0.8239629864692688, 0.9467962980270386, 0.9615926146507263, 0.9669259190559387, 0.9709629416465759, 0.97303706407547, 0.9743888974189758, 0.9764074087142944, 0.9778333306312561, 0.9787963032722473, 0.9792777895927429, 0.9799259305000305, 0.9803333282470703, 0.9815740585327148, 0.9822407364845276, 0.983129620552063, 0.982629656791687, 0.983222246170044, 0.9836296439170837, 0.9836111068725586, 0.984499990940094, 0.984666645526886, 0.9844259023666382, 0.9851852059364319, 0.9852777719497681, 0.9847407341003418, 0.9859259128570557, 0.9851852059364319, 0.9866111278533936, 0.9861481189727783, 0.9861111044883728, 0.9866111278533936, 0.9867963194847107, 0.9864073991775513, 0.9873148202896118, 0.9869999885559082, 0.9865185022354126, 0.9874444603919983, 0.9873148202896118, 0.9876481294631958, 0.987407386302948, 0.987240731716156, 0.988444447517395, 0.9878888726234436, 0.9877592325210571, 0.9890740513801575, 0.9884074330329895, 0.9884814620018005, 0.9878518581390381, 0.9879074096679688, 0.9880740642547607, 0.9881666898727417, 0.9888888597488403, 0.9881296157836914, 0.9892777800559998, 0.9885925650596619, 0.988444447517395, 0.9894074201583862, 0.9890925884246826, 0.9891111254692078, 0.98887038230896, 0.9889814853668213, 0.9887962937355042, 0.9899444580078125, 0.9895926117897034, 0.9891111254692078, 0.9899259209632874, 0.9900555610656738, 0.9889073967933655, 0.9894999861717224, 0.9892407655715942, 0.9893518686294556, 0.9892592430114746, 0.9899629354476929, 0.9892222285270691, 0.9898518323898315, 0.9898518323898315, 0.9894999861717224, 0.989814817905426, 0.9898703694343567, 0.9898333549499512, 0.9898518323898315, 0.9905370473861694, 0.9909444451332092, 0.9900000095367432, 0.9903333187103271, 0.9900555610656738, 0.9902963042259216, 0.990407407283783, 0.9907037019729614, 0.990851879119873, 0.9910555481910706, 0.9902592301368713, 0.9904259443283081, 0.99014812707901, 0.9906296133995056, 0.9910555481910706, 0.9909814596176147, 0.9909814596176147, 0.9905370473861694, 0.9920185208320618, 0.9915925860404968, 0.9915000200271606, 0.9911110997200012, 0.9906481504440308, 0.9907962679862976, 0.9912777543067932, 0.9908148050308228, 0.9906481504440308, 0.991018533706665, 0.9915370345115662, 0.9918333292007446, 0.9909259080886841, 0.991611123085022, 0.9916481375694275, 0.9911110997200012, 0.9913703799247742, 0.9911666512489319, 0.9911110997200012, 0.9911481738090515, 0.9916666746139526, 0.9913889169692993, 0.9917592406272888, 0.9920740723609924, 0.9912037253379822, 0.991018533706665, 0.9916296005249023, 0.9913703799247742, 0.9920555353164673, 0.991518497467041, 0.991351842880249, 0.9920926094055176, 0.991777777671814, 0.9915555715560913, 0.9914259314537048, 0.9918703436851501, 0.9921851754188538, 0.9916296005249023, 0.991611123085022, 0.9920185208320618, 0.9918333292007446, 0.9924259185791016, 0.9913148283958435, 0.992111086845398, 0.9914629459381104, 0.9919259548187256, 0.9917036890983582, 0.9918703436851501, 0.9917222261428833, 0.9921851754188538, 0.9923518300056458, 0.991351842880249, 0.9916666746139526, 0.9926481246948242, 0.991611123085022, 0.9922407269477844, 0.9926481246948242, 0.9922962784767151, 0.992111086845398, 0.9921851754188538, 0.9927963018417358, 0.992222249507904, 0.9918888807296753, 0.9925185441970825, 0.992981493473053, 0.9919259548187256, 0.9923148155212402, 0.9923518300056458, 0.9922778010368347, 0.9924444556236267, 0.9927407503128052, 0.9921481609344482, 0.9923148155212402, 0.9923703670501709, 0.9922407269477844, 0.9922037124633789, 0.9926481246948242, 0.9926111102104187, 0.991611123085022, 0.9922962784767151, 0.9928703904151917, 0.991944432258606, 0.9923703670501709, 0.9928333163261414, 0.9921481609344482, 0.99272221326828, 0.9926481246948242, 0.992814838886261, 0.9921851754188538, 0.9925185441970825, 0.9925925731658936, 0.9923518300056458, 0.9927777647972107, 0.9929074048995972, 0.9920926094055176, 0.9930555820465088, 0.992981493473053, 0.9931666851043701, 0.992222249507904, 0.9927407503128052], 'val_loss': [0.16668151319026947, 0.10981329530477524, 0.08705693483352661, 0.07367850095033646, 0.0699586570262909, 0.05832286924123764, 0.055072616785764694, 0.05477733910083771, 0.0527784638106823, 0.048297226428985596, 0.04816119745373726, 0.04586631804704666, 0.04566030949354172, 0.044396813958883286, 0.04295779764652252, 0.04314086586236954, 0.04219331219792366, 0.043577875941991806, 0.03995802253484726, 0.04074546694755554, 0.03776072338223457, 0.03796545788645744, 0.039183612912893295, 0.04069676995277405, 0.03819502890110016, 0.03743876516819, 0.03745996952056885, 0.0349629670381546, 0.037835195660591125, 0.03861285746097565, 0.035569410771131516, 0.037047699093818665, 0.035224493592977524, 0.03449278324842453, 0.035311076790094376, 0.03423426300287247, 0.034608203917741776, 0.03503226116299629, 0.03467141091823578, 0.03249518573284149, 0.03331359475851059, 0.032523881644010544, 0.03487561643123627, 0.03449026867747307, 0.0336897112429142, 0.03265965357422829, 0.032941628247499466, 0.032699137926101685, 0.032829876989126205, 0.03567883372306824, 0.029061993584036827, 0.03548026457428932, 0.03231504559516907, 0.03149709478020668, 0.03176979720592499, 0.03361686319112778, 0.032310884445905685, 0.03264287859201431, 0.030662555247545242, 0.03152990713715553, 0.03201162442564964, 0.03230440616607666, 0.031057050451636314, 0.03130165487527847, 0.03238806501030922, 0.029789414256811142, 0.030738288536667824, 0.03214975446462631, 0.0317336842417717, 0.02833123318850994, 0.029808351770043373, 0.02743782103061676, 0.028954485431313515, 0.030762426555156708, 0.03231560438871384, 0.0296975988894701, 0.030432263389229774, 0.03426048532128334, 0.0325297936797142, 0.03562526777386665, 0.0329885371029377, 0.03595618158578873, 0.031221996992826462, 0.030843958258628845, 0.030435819178819656, 0.03065088950097561, 0.03150906041264534, 0.03214588761329651, 0.030403099954128265, 0.029400818049907684, 0.030758285894989967, 0.030384819954633713, 0.030450131744146347, 0.029950957745313644, 0.029438557103276253, 0.029716653749346733, 0.03141229227185249, 0.03158654645085335, 0.03130198270082474, 0.032147981226444244, 0.03231792151927948, 0.031604520976543427, 0.03287050500512123, 0.03269828110933304, 0.03134864941239357, 0.031754642724990845, 0.030561968684196472, 0.03317401558160782, 0.03220219165086746, 0.031834933906793594, 0.03494622930884361, 0.03222575783729553, 0.03068968467414379, 0.03157398849725723, 0.031021906062960625, 0.030357105657458305, 0.032054055482149124, 0.031667619943618774, 0.03284210339188576, 0.03268761560320854, 0.032464899122714996, 0.03284155949950218, 0.031403571367263794, 0.03222472593188286, 0.032809093594551086, 0.03245127573609352, 0.03297852724790573, 0.03299262374639511, 0.033765483647584915, 0.03340177237987518, 0.032556332647800446, 0.030626030638813972, 0.03456758335232735, 0.032957568764686584, 0.030426736921072006, 0.03210236504673958, 0.03273295238614082, 0.0321139432489872, 0.030456459149718285, 0.03154505789279938, 0.031108025461435318, 0.03279486671090126, 0.03471365198493004, 0.0329819954931736, 0.03207141533493996, 0.03313583508133888, 0.030820464715361595, 0.031369373202323914, 0.03035641275346279, 0.030569279566407204, 0.030669482424855232, 0.03348234295845032, 0.030514048412442207, 0.03190943971276283, 0.033938582986593246, 0.03222373127937317, 0.03227696940302849, 0.03253369778394699, 0.033168647438287735, 0.03231740742921829, 0.03045041859149933, 0.030978914350271225, 0.03320954740047455, 0.029672568663954735, 0.030741900205612183, 0.030296673998236656, 0.030512791126966476, 0.03436068817973137, 0.030485356226563454, 0.03148144483566284, 0.030132468789815903, 0.031015904620289803, 0.03199588879942894, 0.031438808888196945, 0.03249867632985115, 0.03297977149486542, 0.032910656183958054, 0.03372492641210556, 0.032440535724163055, 0.03222869709134102, 0.03349749743938446, 0.03229997679591179, 0.03343448415398598, 0.03314678370952606, 0.03248954936861992, 0.031919293105602264, 0.03414168208837509, 0.0331193245947361, 0.033688753843307495, 0.03263102099299431, 0.033988699316978455, 0.03593994677066803, 0.03583000600337982, 0.03322519734501839, 0.03204065561294556, 0.030402589589357376, 0.03198351711034775, 0.0310275349766016, 0.032527051866054535, 0.031220274046063423], 'val_accuracy': [0.950166642665863, 0.9664999842643738, 0.971666693687439, 0.9773333072662354, 0.9783333539962769, 0.9816666841506958, 0.98416668176651, 0.9828333258628845, 0.984000027179718, 0.9860000014305115, 0.9860000014305115, 0.987500011920929, 0.9850000143051147, 0.9866666793823242, 0.9866666793823242, 0.9884999990463257, 0.987333357334137, 0.987666666507721, 0.9890000224113464, 0.9886666536331177, 0.9898333549499512, 0.9893333315849304, 0.9893333315849304, 0.9879999756813049, 0.9898333549499512, 0.9901666641235352, 0.9900000095367432, 0.9904999732971191, 0.9891666769981384, 0.9900000095367432, 0.9901666641235352, 0.9900000095367432, 0.9904999732971191, 0.9906666874885559, 0.9900000095367432, 0.9903333187103271, 0.9908333420753479, 0.9900000095367432, 0.9900000095367432, 0.9906666874885559, 0.9906666874885559, 0.9915000200271606, 0.9904999732971191, 0.9903333187103271, 0.9911666512489319, 0.9911666512489319, 0.9909999966621399, 0.9913333058357239, 0.9904999732971191, 0.9909999966621399, 0.9916666746139526, 0.9906666874885559, 0.9916666746139526, 0.9909999966621399, 0.9913333058357239, 0.9909999966621399, 0.9911666512489319, 0.9903333187103271, 0.9913333058357239, 0.9904999732971191, 0.9908333420753479, 0.9904999732971191, 0.9916666746139526, 0.9909999966621399, 0.9915000200271606, 0.9919999837875366, 0.9911666512489319, 0.9901666641235352, 0.9906666874885559, 0.9931666851043701, 0.9923333525657654, 0.9918333292007446, 0.9923333525657654, 0.9916666746139526, 0.9915000200271606, 0.9909999966621399, 0.9915000200271606, 0.9903333187103271, 0.9913333058357239, 0.9898333549499512, 0.9913333058357239, 0.9903333187103271, 0.9918333292007446, 0.9915000200271606, 0.9916666746139526, 0.9909999966621399, 0.9915000200271606, 0.9909999966621399, 0.9916666746139526, 0.9921666383743286, 0.9921666383743286, 0.9918333292007446, 0.9911666512489319, 0.9918333292007446, 0.9923333525657654, 0.9915000200271606, 0.9916666746139526, 0.9908333420753479, 0.9921666383743286, 0.9915000200271606, 0.9916666746139526, 0.9919999837875366, 0.9915000200271606, 0.9911666512489319, 0.9916666746139526, 0.9919999837875366, 0.9925000071525574, 0.9915000200271606, 0.9923333525657654, 0.9919999837875366, 0.9916666746139526, 0.9909999966621399, 0.9916666746139526, 0.9921666383743286, 0.9925000071525574, 0.9919999837875366, 0.9918333292007446, 0.9923333525657654, 0.9918333292007446, 0.9915000200271606, 0.9923333525657654, 0.9919999837875366, 0.9926666617393494, 0.9921666383743286, 0.9923333525657654, 0.9918333292007446, 0.9916666746139526, 0.9921666383743286, 0.9916666746139526, 0.9926666617393494, 0.9928333163261414, 0.9923333525657654, 0.9916666746139526, 0.9915000200271606, 0.9929999709129333, 0.9918333292007446, 0.9916666746139526, 0.9926666617393494, 0.9926666617393494, 0.9918333292007446, 0.9925000071525574, 0.9909999966621399, 0.9928333163261414, 0.9919999837875366, 0.9916666746139526, 0.9925000071525574, 0.9925000071525574, 0.9918333292007446, 0.9931666851043701, 0.9928333163261414, 0.9925000071525574, 0.9911666512489319, 0.9919999837875366, 0.9923333525657654, 0.9925000071525574, 0.9928333163261414, 0.9921666383743286, 0.9919999837875366, 0.9911666512489319, 0.9921666383743286, 0.9923333525657654, 0.9925000071525574, 0.9918333292007446, 0.9926666617393494, 0.9921666383743286, 0.9928333163261414, 0.9926666617393494, 0.9918333292007446, 0.9921666383743286, 0.9926666617393494, 0.9921666383743286, 0.9925000071525574, 0.9926666617393494, 0.9925000071525574, 0.9923333525657654, 0.9921666383743286, 0.9908333420753479, 0.9918333292007446, 0.9926666617393494, 0.9926666617393494, 0.9921666383743286, 0.9925000071525574, 0.9918333292007446, 0.9925000071525574, 0.9928333163261414, 0.9923333525657654, 0.9908333420753479, 0.9919999837875366, 0.9916666746139526, 0.9919999837875366, 0.9923333525657654, 0.9908333420753479, 0.9915000200271606, 0.9911666512489319, 0.9926666617393494, 0.9916666746139526, 0.9923333525657654, 0.9929999709129333, 0.9919999837875366, 0.9915000200271606]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "zw4_DX7rbRRB",
        "outputId": "da504723-7579-4355-b491-b89db33063bf"
      },
      "source": [
        "x_plot = list(range(1,n_epochs+1))\n",
        "plot_history(x_plot, network_history, best_epoch)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEICAYAAABI7RO5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV9f348dc7N3sBIWEGSNiCLImg4EKrolZxC1qFauuo2rr6VVtrqaNL+6u1X2uLX/fC1VpUFAXFDRIgTJlhBQKEhJC97n3//jgn4WbdDHOTIO/n43Ef95zPGfdzTm7O+37G+RxRVYwxxpjmCunoDBhjjDmyWOAwxhjTIhY4jDHGtIgFDmOMMS1igcMYY0yLWOAwxhjTIkENHCLyjIjsF5G1jSwXEXlcRLaIyGoROc5v2UwR2ey+ZvqljxeRNe42j4uIBPMYjDHG1CbBvI9DRE4BioAXVPXYBpafC9wKnAtMBP6mqhNFJAFIB9IABZYD41X1oIh8A/wcWArMBx5X1fcD5SMxMVFTUlLa7sCMMeYosHz58gOqmlQ3PTSYH6qqn4lISoBVpuEEFQWWiEhXEekNnAZ8pKp5ACLyETBVRBYD8aq6xE1/AbgQCBg4UlJSSE9P/45HY4wxRxcR2dFQeke3cfQFdvnNZ7lpgdKzGkivR0SuF5F0EUnPyclp00wbY8zRrKMDR9Co6hxVTVPVtKSkeiUtY4wxrdTRgWM30M9vPtlNC5Se3EC6McaYdtLRgWMecI3bu+oE4JCqZgMLgLNEpJuIdAPOAha4ywpE5AS3N9U1wH87LPfGGHMUCmrjuIi8itPQnSgiWcBvgTAAVf0nTq+oc4EtQAnwY3dZnog8CCxzd/VAdUM58DPgOSAKp1E8YMO4McaYthXU7ridRVpamlqvKmOMaRkRWa6qaXXTO7qqypg2817me5z15lmMfn40Z715Fu9lvtfRWTLmeymoVVXGBJ23EjJe5r2IEGZn/J0ybxkA2cXZzP5qNgDnDTyvAzP4PaQKpQchIg48YbWXHXJ7y3dJrr9dY/uqKoOwqMbXKT4A6/4DScMgeQKERTa+blW5s89G1vH5FBHwH3BCVdm8v4iesRF0kSKI7AIhnublv5l8PqWk0ktsxOFLblmll1CB0Cr3M12lFV48IUJ4aMO/68sqvewrKCMi1EOvLpHkFVfw+eYcIkI9FBw6SFzBZqaccS6R4aHkFVeQEBPepscCFjjMkUIVygshMr52+orn4b07+Vu/vpSF1v5nL/OW8bcVfwte4MjdCtkZgEDPkZA4FKovSAXZsOFd6DUa+k+svV3ORggJhe6DKC6vwuvzEe/Nh5ikw9uDc8wHNsOqV5wAeerdcGAT7PgKko+HvuMh1O+i4PPBzq9hy0LIy4Rh58DgHzgX9/X/dfI5YppzDkvyIONl6NofDu2GFc9T1n0EFX1PIN57EPqmwaApzgX00G7I28qBbmOJz/gX4V8/DuUFaHQiuYMuJurUnxOT2M85H//3A/BVUX7Ji6zwjKJH9scMXP4QUlaAJg4h94R7idu3jKKD+/hH2ExuLPkXSVv/Td6EuwiddCPxvkJ8H/8eObQTiewCY6+EhbNh/3oAqkLC2R1/HF0uf4KufQZTmLWeD96ZS4+SLUzqmo9nTzoVGsoboeexO+FEeg4eS+9evQktO0jRmnfYs+1bhkUcZGBSDOETf0LuyneI27mQxRWjGB+2nfG6Dq+EsrXrJBYm30KiHmTQ/gUkH1zKV1XHkBvag7PittOldBd4K8gP70VhZF/KYpMpjunPa4VjWLmvki6ecv7YbR5j8hdSXlHJKt9AFpUP58JeeXiSBvNa4TgG75zLmSHpJHGQ9Z5hPFZxIUtD0ygsLadPlJcLJg7n4KFDRGZ/Q/+yjaxLOo/ckO58uSWXCq+PHiEFvNH1f/msbCCPlJzPlZ5F3BD6Lt2kiI9WnM6bvW5j0dZiPrnrNPolRLfpV9/aOEx9FSWQ/jQMmAx93eHDfD7I2wq+KojqBmHRsDsdug6A7oOc5d/+F9a8CZN/AeGxsPj3MHQqpJ4K2asgYSAkpELRfucXaYgHtn8JiUMgtsfhz68sgw/vcy5wo6fD5gWw8iXI2QBjr4KzHoLoBKgshb+NhfjejI7IpaFvsgCrU66GkRc52x/cDhNvhMoSyF4NqSc7n7fzayefWxbCO79wAkF0dyjNg9FXOPnevNAJAuqDz/4CO76o9VnatT9y4i2QtQzWvuWsBzDsPNRXhbdvGp6+xyGv/Qi85VQMOpvl23IYXLWZJDnE3siB7OpzLgNGnkCPvZ/CxvehIAsVNyDGJCJF+8E90ipPFOsjxvCvqvM4IyGXH5b8h/CCHVThocjTha7ePOryhUZS1ut4QvavI7Li8PINnqH0rsqii5TUpFWFx5Mj3elZvoMQfJRqOFFSwfq4yeQnpVG18xtOrPwGLyGsCB3LsJBdRGkp+dKFHhVZ7NCeDArJZmtIKjtiRjGm6HO668Ga/S/xHcMJId+yL7QPPav2UEo4Ih7EV8W3pDAgZD/d9BBlhHFPyJ0UlFVxYsh6LvcsplhiyUsYy7F5HwJwUOPYRU/SvYNJ9uRxlnwDQLFG8Kx3Kpd6PqOXHMRHCDnSnUhfcc2xbgodxmDvFg5qPC9Unk68lDDD8zHRUg5AmYaxNnQko3wbiNAyNvj6sUX7UiWh9As5QB/dT08OEiLKOhnCZ/1u4pLdfyKxaj8LOIGD3ijODF9Dki+HHI0nSQqc8ythLA0/gfTiRC4NX0ov3cfb/e5hSs4rdC3dzjZfL/qH7CcMLwDbQvpzX8Td/DhhHV0Te9Nz0yv0KtlEmHjxSSghWkXpgNPJiUolecMzFBJDZq9zGDDt1yT0Tm34f70JjbVxWOA40uVtc36FDjmr9q9VcC7mO76A3cudX5ijL4ceI2DXN7B6rvOLdsqvIK4XFOyBZU87VRBbFkL+DggJg9PugV6j4PO/wK6l9T8/JAzGXAE7l0LuZmcedd59VeCrbDjffcc7v9BXvQoRXeC4q51f4tHd4eA297OE6oskyROci/nKFyGmB1zwOGxaAMueglnzOSv9d2QXZ9f7mN4++HDHrsP7ARh4Ghzc4XzOWQ/Bjq9h43uQcjK6ezmHPN0prIQYKadLdCSegp319lsW3Zv0pItZVDWGvQVlJB5ay+UhHzOKLXhDo9g75EpiJlxN0TcvEbf5bQ5URTDIveVosyazJup4Tin/lBxfHOUJw1lZ2pO0sq8ZxWYAKghjQ9yJLGUUTx0YwQD28efIZ9jeZQIL4i+ldMcKxnrXMC10CQkcAiDdN5RXfWeS1eM0dheH0LtgFaNCttFFivjYOw4Bpnm+5ISQ9eRrHHOirqWirIRyn4fIlOM5OTWW7D27mLuuhCkhGZwUspZkz0E2kMJaX3+u67GJTWEjeDD7eArLvaQmxnBHWjgpG+bQLTcDX1U5d1beQH5UKr/t/hFDPdkciOjH70suIr8yhH5RFcyMXsLuuFEMOfARo3e8wNawIVxQ8lt+c2wuSdmLqSjKZd3gGyiKTSUvP5+zKxexJ2Iw34aP4PThPZg0KJG8TUvo+d8riNBy5sVexrBzfgZdBvCnBRs5dWgSV07sT0zpHsjZROXXTxKWuZDy+BTKz3+S+IHHoyGhbN61h4NLXiG+30iOOfFcKDtEfkUIn2YWMKpvFwaG5sKa1/EmDkdSTiYkuitUFENVObvKIomLDKVLVBgigqpSWlpC5bp3iX//Z4ivCu3Sj4+OeZiX9vTmJyelcvKgbkjxfpbmhBOZ9y2jylcSMupiNL4vOYXlJIWVIs+cAznfOv8PabOo2LuBsJ7DkdRTnP+j137k/E/VEPad+zTdIpTwzfOdH0T9JgCgO5fAN08hG9+HW9Mhvk/D/4dNsMBxJAWOsgL44v851RxDzgJPuFMl4fPBp39yqh3yMiG2JxxyL2qTb3N+uS950gkmIaEQGgHF+53l4gH1QngcVBRCWIzzJfSEQ7cUJ/hUlybi+8CUX0P6M86vfXDST73b+cySXCjLh95jYc0bsPo16H8ipF0Hg8+A9+50qpWm/S/syXB+5fcZ5wSWgmwIi0S/eAwpOQAn3Ax7V8P2zyFpuFOfXVEEF/6DtZV92fTV25QNOIPxaSeQ3C2K1999j6nr76a31wkSOvoKtp70F1bmfcyf0x+qaeMACCGcqT1v5WdDT2TjJ6+wQ3vRg1wuyPoLJRGJZIf1Z3CR871Y2eUHjCr4lP2+Lkwr/x19klPYsLeQEPFxivcb4qWEZaFpHFu5hggqecd3IlUSxsCkWFK6R9MvIZp1WYco25nObk0kl8N11jHhHs4e2YvTPBkM2vchC/v+jE92C+v3FPD3K8dx9sheNetm7drJqvTPeHV3IlsKwujdNZLThvagT9dIFqzbR2ZOEZU+H5MGJnL+mD5M6hdJyPp/s7UygTfzBnHlxAH0S4jG51O+zsylrNK5wGcfKuNgSQWq4FMluVs0x/Xvis+dD/Mcrk9fufMg6/Y4v4qnje1DTHgoFV4fkWFOyUdVKSitIjYyFE9I7R8rDbUhNMjng4yX8A48ncLwHnSNblk9vC93G5VeLxE9BgdeUdX5EdJjRP1qzmDY+AFs/hBOv88pFbdE/i5Y/Ec48WboOaL+8vXzYOsiOPEW53+1ssT5ARZIRQmEt76aygJHZwscPh/uf5gzX5IHX/7NuTCvegX2rjm8roTAyXc6v8Y/uAdSTnaCStFeSDrGCR4rXnDW7TPOuYh7K52L+9CpTvBRHyz9FxRmQ8pJMPRsp8ros0ed9eL7wqRboduAw5+r6vwqz98FvUZRFdGVPy/YSEx4KD8+KYWY8FBCBMRbWbuuHcgtKmfBun2cPCSR3fml3PXGKiYPSuSnp6QS7vHw29e/IHvnVqqSRtAtKpRYTyUpvZPwAJWVZURFxfDMl9uI8IRQWO78yooO91BS4WVKSgTHHvyYhUX9qep+DJv3FwEQ1S2DkIQPkLB8tLIrmncOJQfHABDuCaFnlwgOFlfSq2I7+7UrEZHRPCKPszkklWdCryBZ9zE4uQfXTT2BwT1i2bi3kKe/yCQlMYaY8FA27Sukb7coBibGkhQXztCeccRFhvmdLuXTTTlUeZWIsBDW7ymgX0I0pw/vUXPR9Vfp9dW6YBvT2Vjg6EyBw1sJL1wIVaUw/VXnovvCNKcdAJzSwGXPgScU9qx00qsbN4dOhRmv1q6W8vmcEkpMEoy7GkJadzGqqPIR5pGa4vcfP9jAW8t3c8lxfZk0OJE3l2fxzqo9AIQI+BSG9Ihl1uQU4iLDyC+pYH9BOdmHyliwbi9F5VVOzxCFxNhwDhRVUOF16v2jwz1cNbE/W3OKKa3wUlxRxaZ9hQBEhnnIL6lkQkoC/7p6PFU+5b3Ve8jYlc/VJ6YwfkA3CssquW1uBrvzS5kxoT9F5VXkl1TQNTqcskovXaPDmTGhH19tyWXjvkIuHZ9Mz/hIqrw+1mcX0DUqnH4JUU3/MjbmKGaBoyMCR0UJ/OcGSD0FJvz0cPqiB+HzR8ET4XRprCx16jCveBl6DHcanmMSD6/v88H8uyDzE7juo9rLmlDp9RHiXhxfXrqDrfuLGJ+SwJRhSWzNKebPH2xAFUoqvazdfYioMA+DkmKICPXwzfY8RvXtwvrsArw+53tyzznDOWlwIvPXZBMaIny4fh8b9hbWfJ4nREiMDee4/t2YOSmF15ftorC8ikcvHUNxRRVfbDlAblEFU4/tRWpiTK28qmrNhby4vIrocI9d2I3pQBY42jNwVBRD0T748DdOl8ywaLglHRb8CrZ/4bQRjL0Kjr8WPvm908Yw+oqahq1GqdYqafh8SkiIUFbp5c43VuHzKWeP7EWXqDCWZOayYN1edh0sJTYilJ7xEWzaV0REaAjlVT4iw0Ko9CpJsRH07RaFR4TjBnSjtKKKrTnFZB0s4bK0fvzstEHkFlew/UAx4aEhjE7uWitLPp/TB94TAl2iwkmICa9X722MOTJZ4GivwFG0H/55khM4wGnIWvKk03ZRuAdGXe60I0y+DSJim73biiofG/YWUFBaxYg+8WQfKuW659JJ7hZFdEQon2/OISE6nNziCsD55X/q0CRG9I5nb0EZ6/cUcN1JqUwb24eMXfn8N2MPnhDh9jOH0iUqrIlPN8YcjRoLHHYDYFubfxeU5sMP/wrdUp2bqMoLnRvVJtwA5/65yV14fcoHa/eyaV8hlV4fPeMjeebLbezIdfqdh4eGEBoixEeGsT23hANF5TwwbSRXTujPpn1FlFZ6GdA9msTYiAb3n5aSQFpKC3t8GGOMywLHd7X0X5D+rNNgve1TpxH7jN9C2rWH1znzd05vp7FXNbqb3KJylmTmUeH18vKSnaTvOIgIeESo8imDe8Tyt+ljSYyNYMG6vWw7UMyfLhlNXGQoW3OKGdvPqUIa0acduhwaY45qVlX1XZTkwWOjnfsiohKcu4wHToGr3nR6RDWisKySv360mYKySk4c2J15q/bw+eYc3PZn4iJDmX3+SM4f49y0k3WwhH4J0dZ10xjTrqyqKhi++Ktzs9rFT8EH9zrDY1zw90aDhtenvLt6D3/+YCPZh0qJCQ/lzeVZJMZGcPOUwZxxTE/iI0NJiouodX/AwKTmt4UYY0ywWeBoreJc+GaO0xtq9OVw7CUBR9Q8WFzBtc8vY+XOfIb3iuPvV05iRO941u4+xKjkLkSEtu1onMYYEywWOFpr9VxnOOjJP3fmGwkaFVU+lmTm8vB737Itt5i/XDaGi8b1JcTtsmqN1MaYI40FjtZQdYb46JvmDLzXgIKySl77Zhf/+iyTA0XlxEWG8tys45k0uPk37xljTGdkgaM1dn3jDNF9wd/rLTpUUslD761n3qo9lFf5OGlwIjMnjeLkIYkNjldkjDFHGgscLZWzCd75uTPK7MiLay1at+cQ17+wnH0FZcyY0J/L0pLr3WltjDFHuqD27xSRqSKyUUS2iMg9DSwfICKLRGS1iCwWkWQ3fYqIZPi9ykTkQnfZcyKyzW/Z2GAeQy0lec4TzooPwPSXat35nZlTxDVPf4NPlTdvmsSDFx5rQcMY870UtBKHiHiAJ4AzgSxgmYjMU9X1fqs9Crygqs+LyOnAH4CrVfUTYKy7nwRgC/Ch33a/VNU3g5X3Ru34EsoPwaz5kDK5JrmwrJKZzzpPHHv5JxOt+6wx5nstmCWOCcAWVc1U1QpgLjCtzjojgI/d6U8aWA5wKfC+qpY0sKx97VzijGibXPt+mD99sIGsg6XMuWa8BQ1jzPdeMANHX2CX33yWm+ZvFVDdUHARECci3eusMx14tU7aw2711l9FpMEBmUTkehFJF5H0nJyc1h1BXbuWOs/gDj38kV9tOcBLS3Zy7eRUxg+wrrXGmO+/jh7D4i7gVBFZCZwK7Ab3yeyAiPQGRgEL/La5FxgOHA8kAHc3tGNVnaOqaaqalpSU9N1zWlnqPAa138SapNVZ+dzw4nIGJsZw51lDv/tnGGPMESCYvap2A/385pPdtBqquge3xCEiscAlqprvt8rlwH9UtdJvm2x3slxEnsUJPsG3Z6XzsKX+JwCwv6CMmc98Q3xUGC/+ZCLR4dZBzRhzdAhmiWMZMEREUkUkHKfKaZ7/CiKSKCLVebgXeKbOPmZQp5rKLYUgzqPhLgTWBiHv9e382nl3Sxyz31lHcYWX56+dQN+uUe2SBWOM6QyCFjhUtQq4Baea6VvgdVVdJyIPiMgF7mqnARtFZBPQE3i4ensRScEpsXxaZ9cvi8gaYA2QCDwUrGOoZcfXkDgUohP4eMM+5q/Zyy/OGMLgHtYYbow5ugS1fkVV5wPz66Td7zf9JtBgt1pV3U79xnRU9fS2zWUzeCudEsfoywF45ovt9E+I5qcnD2z3rBhjTEfr6MbxI8OeDGf49JSTOVhcwdeZuZw/pjfhoXb6jDFHH7vyNcf2z5z3lJP5aP0+vD7lnGN7d2yejDGmg1jgaI5tn0PSMRCbxPtrs0nuFsVIe0SrMeYoZYGjKVUVzo1/qSdTWFbJl1tyOefYXjiduowx5uhjgaMpBzZCZQn0m0j69oNUeH1MGd6jo3NljDEdxgJHU4r2O+/xfViyLZcwj3Bc/24dmydjjOlAFjiaUpLnvEcnsjQzjzHJXe2BTMaYo5oFjqaUHACgOLQLa3YfYuJAG8jQGHN0s8DRlJJckBCW7wevT5mYWnfwXmOMObpY4GhK8QGISuCb7fl4QoTxA6x9wxhzdLPA0ZSSXIjuzsZ9hQxKiiEmwkbBNcYc3SxwNKUkF2ISyS0qJymuwWdGGWPMUcUCR1NKciE6gQNFFSTGWuAwxhgLHE0pPgDRiRwoKrfAYYwxWOAIzOeD0jwqI7pRUuGle2x4R+fIGGM6nAWOQMryQX0UhXYFsBKHMcZggSOwklwA8sUZCTfRShzGGGOBI6Bi567xPK0OHFbiMMYYCxyBuCWOHG8MYIHDGGPAAkdg7jhVeyudwJEQY1VVxhhjgSMQt8SRVRFDXGSojYprjDEEOXCIyFQR2SgiW0TkngaWDxCRRSKyWkQWi0iy3zKviGS4r3l+6akistTd52siErxiQHEuhMWQXQJJVk1ljDFAEAOHiHiAJ4BzgBHADBEZUWe1R4EXVHU08ADwB79lpao61n1d4Jf+J+CvqjoYOAhcF6xjoOQAxHQnt6jc7uEwxhhXMEscE4AtqpqpqhXAXGBanXVGAB+70580sLwWcR70fTrwppv0PHBhm+W4LneAQxtuxBhjDgtm4OgL7PKbz3LT/K0CLnanLwLiRKT6gReRIpIuIktEpDo4dAfyVbUqwD4BEJHr3e3Tc3JyWncEU/8I5/+NA1biMMaYGh3dOH4XcKqIrAROBXYDXnfZAFVNA64EHhORQS3ZsarOUdU0VU1LSkpqXe4Sh1DZYxT5JZVW4jDGGFcwHy6xG+jnN5/sptVQ1T24JQ4RiQUuUdV8d9lu9z1TRBYD44C3gK4iEuqWOurts63lFVcAdg+HMcZUC2aJYxkwxO0FFQ5MB+b5ryAiiSJSnYd7gWfc9G4iElG9DjAZWK+qitMWcqm7zUzgv0E8Bg6WOIGjW7RVVRljDAQxcLglgluABcC3wOuquk5EHhCR6l5SpwEbRWQT0BN42E0/BkgXkVU4geKPqrreXXY3cIeIbMFp83g6WMcAUOVVAEI9EsyPMcaYI0ZQn4OqqvOB+XXS7vebfpPDPaT81/kKGNXIPjNxemy1C586gcMjFjiMMQY6vnG80/M5cYMQO1PGGANY4GiS140cIVbiMMYYwAJHk2qqqkIscBhjDFjgaFJ1icPaOIwxxmGBownVJQ6xwGGMMYAFjib5fM67VVUZY4zDAkcTvDVtHB2cEWOM6STsctgEn/WqMsaYWixwNKG6jcMChzHGOCxwNKGmV5W1cRhjDGCBo0lW4jDGmNoscDShesgRK3EYY4zDAkcTDg850sEZMcaYTsICRxNqqqoschhjDGCBo0k25IgxxtRmgaMJNcOqW+AwxhjAAkeTam4AtDNljDGABY4meW1YdWOMqcUCRxOsjcMYY2qzwNEEtWHVjTGmlqAGDhGZKiIbRWSLiNzTwPIBIrJIRFaLyGIRSXbTx4rI1yKyzl12hd82z4nINhHJcF9jg3kMNuSIMcbUFrTAISIe4AngHGAEMENERtRZ7VHgBVUdDTwA/MFNLwGuUdWRwFTgMRHp6rfdL1V1rPvKCNYxAHir7xy3EocxxgDNCBwicr6ItCbATAC2qGqmqlYAc4FpddYZAXzsTn9SvVxVN6nqZnd6D7AfSGpFHr4zVetVZYwx/ppzObwC2CwifxaR4S3Yd19gl998lpvmbxVwsTt9ERAnIt39VxCRCUA4sNUv+WG3CuuvIhLR0IeLyPUiki4i6Tk5OS3Idm1eex6HMcbU0mTgUNUfAeNwLtzPuW0P14tIXBt8/l3AqSKyEjgV2A14qxeKSG/gReDHquo+xJV7geHA8UACcHcj+Z6jqmmqmpaU1PrCinXHNcaY2ppVAaOqBcCbONVNvXFKBytE5NYAm+0G+vnNJ7tp/vvdo6oXq+o44NduWj6AiMQD7wG/VtUlfttkq6MceBanSixo7AmAxhhTW3PaOC4Qkf8Ai4EwYIKqngOMAe4MsOkyYIiIpIpIODAdmFdn34l+7Sf3As+46eHAf3Aazt+ss01v912AC4G1TR3Dd3F4yJFgfooxxhw5QpuxziXAX1X1M/9EVS0Rkesa20hVq0TkFmAB4AGeUdV1IvIAkK6q84DTgD+IiAKfATe7m18OnAJ0F5FZbtostwfVyyKSBAiQAdzYvENtHeuOa4wxtTUncMwGsqtnRCQK6Kmq21V1UaANVXU+ML9O2v1+02/iVIHV3e4l4KVG9nl6M/LcZnyqiNgNgMYYU605bRxvAD6/ea+bdlTw+tTu4TDGGD/NCRyh7n0YALjT4cHLUufiU2sYN8YYf80JHDkickH1jIhMAw4EL0udi0/Vbv4zxhg/zWnjuBGnQfp/cRqkdwHXBDVXnYhVVRljTG1NBg5V3QqcICKx7nxR0HPViXh9as8bN8YYP80pcSAi5wEjgcjq3kWq+kAQ89VpqKq1cRhjjJ/m3AD4T5zxqm7Fqaq6DBgQ5Hx1Gl5Vu4fDGGP8NKfZd5KqXgMcVNXfAScCQ4Obrc7D67NeVcYY4685gaPMfS8RkT5AJc54VUcFVcVjvaqMMaZGc9o43nEfovQIsAJQ4Kmg5qoT8fqsjcMYY/wFDBzuAISL3BFr3xKRd4FIVT3ULrnrBLzWOG6MMbUErIRxn4HxhN98+dEUNMAZVt0ax40x5rDm1N4vEpFL5Cgd5c8ZcqSjc2GMMZ1HcwLHDTiDGpaLSIGIFIpIQZDz1Wl41W4ANMYYf825c7wtHhF7xPLZkCPGGFNLk4FDRE5pKL3ug52+r7zWxmGMMbU0pzvuL/2mI3Ge8b0caNcHKnUUn9pDnIwxxl9zqqrO958XkX7AY0HLUSfjsxsAjTGmltZcErOAY9o6I52VDatujDG1NaeN4+84d4uDE2jG4txBflTwWa8qY4yppTkljnScNo3lwNfA3ar6o0umZsoAABibSURBVObsXESmishGEdkiIvc0sHyAiCwSkdUislhEkv2WzRSRze5rpl/6eBFZ4+7z8WDfX+KzO8eNMaaW5jSOvwmUqaoXQEQ8IhKtqiWBNhIRD85d52fiVG8tE5F5qrreb7VHgRdU9XkROR34A3C1iCQAvwXScEo7y91tDwJPAj8FlgLzganA+80/5JaxqipjjKmtWXeOA1F+81HAwmZsNwHYoqqZqloBzAWm1VlnBPCxO/2J3/KzgY9UNc8NFh8BU0WkNxCvqktUVYEXgAubkZdW8/mwZ44bY4yf5lwSI/0fF+tORzdju744zyevluWm+VsFXOxOXwTEiUj3ANv2dacD7RMAEbleRNJFJD0nJ6cZ2W2Yzx7kZIwxtTQncBSLyHHVMyIyHihto8+/CzhVRFYCpwK7AW9b7FhV56hqmqqmJSUltXo/NjquMcbU1pw2jtuAN0RkD86jY3vhPEq2KbuBfn7zyW5aDVXdg1viEJFY4BJVzReR3cBpdbZd7G6fXCe91j7bms+ex2GMMbU05wbAZSIyHBjmJm1U1cpm7HsZMEREUnEu7tOBK/1XEJFEIM8dvv1e4Bl30QLg9yLSzZ0/C7hXVfPcgRZPwGkcvwb4ezPy0mr2zHFjjKmtyaoqEbkZiFHVtaq6FogVkZ81tZ2qVgG34ASBb4HXVXWdiDwgIhe4q50GbBSRTUBP4GF32zzgQZzgswx4wE0D+Bnwf8AWYCtB7FEFbuO4xQ1jjKkhTuekACuIZKjq2DppK1V1XFBz1obS0tI0PT29VdtOfewz+idEM+eatDbOlTHGdG4islxV6138mtM47vG/yc69PyO8LTPXmdnouMYYU1tzGsc/AF4TkX+58zcQ5OqhzsQe5GSMMbU1J3DcDVwP3OjOr8bpWXVUUMV6VRljjJ8mq6rcHk9Lge04d4OfjtPYfVRwhhzp6FwYY0zn0WiJQ0SGAjPc1wHgNQBVndI+WescvD6rqjLGGH+Bqqo2AJ8DP1TVLQAicnu75KoTUbVBDo0xxl+gqqqLgWzgExF5SkTOwLlz/KhiQ44YY0xtjQYOVX1bVacDw3FGrr0N6CEiT4rIWe2VwY7m9WFVVcYY46c5jePFqvqK++zxZGAlTk+ro4I9c9wYY2pr0SVRVQ+6o86eEawMdTb2BEBjjKnNfks3wWuj4xpjTC0WOJrgsyFHjDGmFgscTbBh1Y0xpjYLHE3wKVhNlTHGHGaBowk+n90AaIwx/ixwNMGqqowxpjYLHAGoqo2Oa4wxdVjgCMDnPhzRAocxxhxmgSMArxs57M5xY4w5zC6JAfjc57HbWFXGGHNYUAOHiEwVkY0iskVE7mlgeX8R+UREVorIahE5102/SkQy/F4+ERnrLlvs7rN6WY9g5b86cFivKmOMOaw5j45tFRHxAE8AZwJZwDIRmaeq6/1Wuw94XVWfFJERwHwgRVVfBl529zMKeFtVM/y2u0pV04OV92rVVVXWxmGMMYcFs8QxAdiiqpmqWgHMBabVWUeBeHe6C7Cngf3McLdtdz6f825VVcYYc1gwA0dfYJfffJab5m828CMRycIpbdzawH6uAF6tk/asW031G5GGiwMicr2IpItIek5OTqsOwFtTVdWqzY0x5nupoxvHZwDPqWoycC7woojU5ElEJgIlqrrWb5urVHUUcLL7urqhHbvDv6epalpSUlKrMmeN48YYU18wA8duoJ/ffLKb5u864HUAVf0aiAQS/ZZPp05pQ1V3u++FwCs4VWJB4bM2DmOMqSeYgWMZMEREUkUkHCcIzKuzzk7gDAAROQYncOS48yHA5fi1b4hIqIgkutNhwA+BtQRJTVWVlTiMMaZG0HpVqWqViNwCLAA8wDOquk5EHgDSVXUecCfwlIjcjtNQPkvVvVrDKcAuVc30220EsMANGh5gIfBUsI6h5gZAK3EYY0yNoAUOAFWdj9Po7Z92v9/0emByI9suBk6ok1YMjG/zjDaiOoRZ3DDGmMM6unG8Uzs85IhFDmOMqWaBIwBr4zDGmPoscARQ3dxivaqMMeYwCxwBeKvvHLfAYYwxNSxwBGDDqhtjTH12SQzAZ1VVxhhTjwWOAHzWOG6MMfVY4AjAhlU3xpj6LHAEYIMcGmNMfRY4AqjuVWVDjhhjzGEWOAI43DjewRkxxphOxAJHADXDqlvkMMaYGhY4ArAhR4wxpj4LHAG4BQ7rVWWMMX4scARw+AmAHZwRY4zpRCxwBGDDqhtjTH0WOALw2pAjxhhTjwWOANQax40xph4LHAHYsOrGGFOfBY4ADnfH7eCMGGNMJxLUS6KITBWRjSKyRUTuaWB5fxH5RERWishqETnXTU8RkVIRyXBf//TbZryIrHH3+bhI8IoDPhvk0Bhj6gla4BARD/AEcA4wApghIiPqrHYf8LqqjgOmA//wW7ZVVce6rxv90p8EfgoMcV9Tg3UMNqy6McbUF8wSxwRgi6pmqmoFMBeYVmcdBeLd6S7AnkA7FJHeQLyqLlGn5foF4MK2zfZhNqy6McbUF8zA0RfY5Tef5ab5mw38SESygPnArX7LUt0qrE9F5GS/fWY1sU8AROR6EUkXkfScnJxWHYANq26MMfV1dLPvDOA5VU0GzgVeFJEQIBvo71Zh3QG8IiLxAfZTj6rOUdU0VU1LSkpqVeZsWHVjjKkvNIj73g3085tPdtP8XYfbRqGqX4tIJJCoqvuBcjd9uYhsBYa62yc3sc82Y8OqG2NMfcEMHMuAISKSinNxnw5cWWedncAZwHMicgwQCeSISBKQp6peERmI0wieqap5IlIgIicAS4FrgL8H6wCsqsqYzqeyspKsrCzKyso6OivfG5GRkSQnJxMWFtas9YMWOFS1SkRuARYAHuAZVV0nIg8A6ao6D7gTeEpEbsdpKJ+lqioipwAPiEgl4ANuVNU8d9c/A54DooD33VdQ1IxVZVVVxnQaWVlZxMXFkZKSQhB74x81VJXc3FyysrJITU1t1jbBLHGgqvNxGr390+73m14PTG5gu7eAtxrZZzpwbNvmtGE1w6pbicOYTqOsrMyCRhsSEbp3705LOhF1dON4p2bDqhvTOVnQaFstPZ8WOAKwJwAaY0x9FjgCsBsAjTF15ebmMnbsWMaOHUuvXr3o27dvzXxFRUXAbdPT0/n5z3/e5GdMmjSprbIbFEFt4zjS2bDqxpi6unfvTkZGBgCzZ88mNjaWu+66q2Z5VVUVoaENX1rT0tJIS0tr8jO++uqrtslskFjgCMCGVTemc/vdO+tYv6egTfc5ok88vz1/ZIu2mTVrFpGRkaxcuZLJkyczffp0fvGLX1BWVkZUVBTPPvssw4YNY/HixTz66KO8++67zJ49m507d5KZmcnOnTu57bbbakojsbGxFBUVsXjxYmbPnk1iYiJr165l/PjxvPTSS4gI8+fP54477iAmJobJkyeTmZnJu+++26bnojEWOALw2g2AxphmysrK4quvvsLj8VBQUMDnn39OaGgoCxcu5Fe/+hVvvVW/o+iGDRv45JNPKCwsZNiwYdx000317qVYuXIl69ato0+fPkyePJkvv/yStLQ0brjhBj777DNSU1OZMWNGex0mYIEjIJ9PCRHrwWFMZ9XSkkEwXXbZZXg8HgAOHTrEzJkz2bx5MyJCZWVlg9ucd955REREEBERQY8ePdi3bx/Jycm11pkwYUJN2tixY9m+fTuxsbEMHDiw5r6LGTNmMGfOnCAeXW3WOB6AT9WqqYwxzRITE1Mz/Zvf/IYpU6awdu1a3nnnnUbvco+IiKiZ9ng8VFVVtWqd9maBIwCvqt38Z4xpsUOHDtG3rzNw93PPPdfm+x82bBiZmZls374dgNdee63NPyMQCxwB+Hxqw40YY1rsf/7nf7j33nsZN25cUEoIUVFR/OMf/2Dq1KmMHz+euLg4unTp0uaf0xip7nL6fZaWlqbp6ekt3u7Bd9fz2rJdrP3d2UHIlTGmNb799luOOeaYjs5GhysqKiI2NhZV5eabb2bIkCHcfvvtrd5fQ+dVRJarar3+w1biCMDrU6zAYYzpjJ566inGjh3LyJEjOXToEDfccEO7fbb1qgrAp2o3/xljOqXbb7/9O5UwvgsrcQTgtTYOY4ypxwJHAD61IdWNMaYuCxwBVN8AaIwx5jALHAF41aqqjDGmLgscAfh8dgOgMaa2KVOmsGDBglppjz32GDfddFOD65922mlU3w5w7rnnkp+fX2+d2bNn8+ijjwb83Lfffpv169fXzN9///0sXLiwpdlvExY4ArBeVcaYumbMmMHcuXNrpc2dO7dZAw3Onz+frl27tupz6waOBx54gB/84Aet2td3Zd1xA/CqDaluTKf2/j2wd03b7rPXKDjnj40uvvTSS7nvvvuoqKggPDyc7du3s2fPHl599VXuuOMOSktLufTSS/nd735Xb9uUlBTS09NJTEzk4Ycf5vnnn6dHjx7069eP8ePHA879GXPmzKGiooLBgwfz4osvkpGRwbx58/j000956KGHeOutt3jwwQf54Q9/yKWXXsqiRYu46667qKqq4vjjj+fJJ58kIiKClJQUZs6cyTvvvENlZSVvvPEGw4cP/86nyEocAVjjuDGmroSEBCZMmMD7778POKWNyy+/nIcffpj09HRWr17Np59+yurVqxvdx/Lly5k7dy4ZGRnMnz+fZcuW1Sy7+OKLWbZsGatWreKYY47h6aefZtKkSVxwwQU88sgjZGRkMGjQoJr1y8rKmDVrFq+99hpr1qyhqqqKJ598smZ5YmIiK1as4KabbmqyOqy5glriEJGpwN8AD/B/qvrHOsv7A88DXd117lHV+SJyJvBHIByoAH6pqh+72ywGegOl7m7OUtX9wci/12dVVcZ0agFKBsFUXV01bdo05s6dy9NPP83rr7/OnDlzqKqqIjs7m/Xr1zN69OgGt//888+56KKLiI6OBuCCCy6oWbZ27Vruu+8+8vPzKSoq4uyzAw95tHHjRlJTUxk6dCgAM2fO5IknnuC2224DnEAEMH78eP79739/52OHIAYOEfEATwBnAlnAMhGZp6rr/Va7D3hdVZ8UkRHAfCAFOACcr6p7RORYYAHQ12+7q1S15YNPtZANq26Maci0adO4/fbbWbFiBSUlJSQkJPDoo4+ybNkyunXrxqxZsxodSr0ps2bN4u2332bMmDE899xzLF68+DvltXpY9rYckj2YVVUTgC2qmqmqFcBcYFqddRSId6e7AHsAVHWlqu5x09cBUSISQTuzwGGMaUhsbCxTpkzh2muvZcaMGRQUFBATE0OXLl3Yt29fTTVWY0455RTefvttSktLKSws5J133qlZVlhYSO/evamsrOTll1+uSY+Li6OwsLDevoYNG8b27dvZsmULAC+++CKnnnpqGx1pw4IZOPoCu/zms6hdagCYDfxIRLJwShu3NrCfS4AVqlrul/asiGSIyG+kkcfzicj1IpIuIuk5OTmtOgCrqjLGNGbGjBmsWrWKGTNmMGbMGMaNG8fw4cO58sormTx5csBtjzvuOK644grGjBnDOeecw/HHH1+z7MEHH2TixIlMnjy5VkP29OnTeeSRRxg3bhxbt26tSY+MjOTZZ5/lsssuY9SoUYSEhHDjjTe2/QH7Cdqw6iJyKTBVVX/izl8NTFTVW/zWucPNw19E5ETgaeBYVfW5y0cC83DaMba6aX1VdbeIxAFvAS+p6guB8tLaYdWf+GQLReVV3D31u/dCMMa0DRtWPThaMqx6MBvHdwP9/OaT3TR/1wFTAVT1axGJBBKB/SKSDPwHuKY6aLjr7XbfC0XkFZwqsYCBo7VunjI4GLs1xpgjWjCrqpYBQ0QkVUTCgek4pQd/O4EzAETkGCASyBGRrsB7OL2svqxeWURCRSTRnQ4DfgisDeIxGGOMqSNogUNVq4BbcHpEfYvTe2qdiDwgItV9z+4Efioiq4BXgVnq1J3dAgwG7nfbMjJEpAcQASwQkdVABk4J5qlgHYMxpnM6Gp5c2p5aej7t0bHGmCPKtm3biIuLo3v37jTSN8a0gKqSm5tLYWEhqamptZZ1RBuHMca0ueTkZLKysmhtb0lTX2RkJMnJyc1e3wKHMeaIEhYWVu+XsWlfNlaVMcaYFrHAYYwxpkUscBhjjGmRo6JXlYjkADtasWkizoCLnY3lq2UsXy3XWfNm+WqZ75qvAaqaVDfxqAgcrSUi6Q11Retolq+WsXy1XGfNm+WrZYKVL6uqMsYY0yIWOIwxxrSIBY7A5nR0Bhph+WoZy1fLdda8Wb5aJij5sjYOY4wxLWIlDmOMMS1igcMYY0yLWOBogIhMFZGNIrJFRO7pwHz0E5FPRGS9iKwTkV+46bNFZLffkPPndkDetovIGvfz0920BBH5SEQ2u+/dOiBfw/zOS4aIFIjIbR1xzkTkGRHZLyJr/dIaPEfieNz9zq0WkePaOV+PiMgG97P/4z4TBxFJEZFSv/P2z2DlK0DeGv3bici97jnbKCJnt3O+XvPL03YRyXDT2+2cBbhGBPd7pqr28nsBHmArMBAIB1YBIzooL72B49zpOGATMALnWe13dfB52g4k1kn7M87DtwDuAf7UCf6We4EBHXHOgFOA44C1TZ0j4FzgfUCAE4Cl7Zyvs4BQd/pPfvlK8V+vg85Zg387939hFc5zelLd/1tPe+WrzvK/APe39zkLcI0I6vfMShz1TQC2qGqmqlYAc4FpHZERVc1W1RXudCHOA7H6dkRemmka8Lw7/TxwYQfmBZynS25V1daMGvCdqepnQF6d5MbO0TTgBXUsAbqKSO/2ypeqfqjOw9cAluA86rndNXLOGjMNmKuq5aq6DdiC8//brvkS56Egl+M8jK5dBbhGBPV7ZoGjvr7ALr/5LDrBxVpEUoBxwFI36Ra3qPlMR1QJAQp8KCLLReR6N62nqma703uBnh2QL3/Tqf3P3NHnDBo/R53pe3ctzq/SaqkislJEPhWRkzsoTw397TrLOTsZ2Keqm/3S2v2c1blGBPV7ZoHjCCAiscBbwG2qWgA8CQwCxgLZOMXk9naSqh4HnAPcLCKn+C9Up1zcYX29xXnO/QXAG25SZzhntXT0OWqIiPwaqAJedpOygf6qOg64A3hFROLbOVud7m9Xxwxq/0Bp93PWwDWiRjC+ZxY46tsN9PObT3bTOoSIhOF8IV5W1X8DqOo+VfWqqg/nmetBKZ4Hoqq73ff9wH/cPOyrLva67/vbO19+zgFWqOo+6BznzNXYOerw752IzAJ+CFzlXmxwq4Fy3enlOO0IQ9szXwH+dp3hnIUCFwOvVae19zlr6BpBkL9nFjjqWwYMEZFU91frdGBeR2TErTt9GvhWVf+fX7p/neRFwNq62wY5XzEiElc9jdOwuhbnPM10V5sJ/Lc981VHrV+BHX3O/DR2juYB17i9Xk4ADvlVNQSdiEwF/ge4QFVL/NKTRMTjTg8EhgCZ7ZUv93Mb+9vNA6aLSISIpLp5+6Y98wb8ANigqlnVCe15zhq7RhDs71l7tPwfaS+cngebcH4p/LoD83ESThFzNZDhvs4FXgTWuOnzgN7tnK+BOL1ZVgHrqs8R0B1YBGwGFgIJHXTeYoBcoItfWrufM5zAlQ1U4tQlX9fYOcLp5fKE+51bA6S1c7624NR9V3/P/umue4n7N84AVgDnd8A5a/RvB/zaPWcbgXPaM19u+nPAjXXWbbdzFuAaEdTvmQ05YowxpkWsqsoYY0yLWOAwxhjTIhY4jDHGtIgFDmOMMS1igcMYY0yLWOAwppVExCu1R+Jts5GU3RFWO+peE2MCCu3oDBhzBCtV1bEdnQlj2puVOIxpY+6zGf4szvNKvhGRwW56ioh87A7Wt0hE+rvpPcV5BsYq9zXJ3ZVHRJ5yn7PwoYhEuev/3H3+wmoRmdtBh2mOYhY4jGm9qDpVVVf4LTukqqOA/wUec9P+DjyvqqNxBhF83E1/HPhUVcfgPPNhnZs+BHhCVUcC+Th3JIPzfIVx7n5uDNbBGdMYu3PcmFYSkSJVjW0gfTtwuqpmugPQ7VXV7iJyAGe4jEo3PVtVE0UkB0hW1XK/faQAH6nqEHf+biBMVR8SkQ+AIuBt4G1VLQryoRpTi5U4jAkObWS6Jcr9pr0cbpM8D2e8oeOAZe4Irca0GwscxgTHFX7vX7vTX+GMtgxwFfC5O70IuAlARDwi0qWxnYpICNBPVT8B7ga6APVKPcYEk/1SMab1okQkw2/+A1Wt7pLbTURW45QaZrhptwLPisgvgRzgx276L4A5InIdTsniJpyRWBviAV5yg4sAj6tqfpsdkTHNYG0cxrQxt40jTVUPdHRejAkGq6oyxhjTIlbiMMYY0yJW4jDGGNMiFjiMMca0iAUOY4wxLWKBwxhjTItY4DDGGNMi/x8NIWeTubWqFQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f77JKlLIBNK2"
      },
      "source": [
        "### Comments\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5wDnEzRBcDd"
      },
      "source": [
        "As we can see, the model converges quickly, and then tends to improve very slowly. This is the best result I was able to obtain with this configuration, as with lower learning rates the convergence was slower, while with higher learning rates we had a strong instability.\n",
        "In general, the two curves tend to be very close together, and therefore there is not a strong sign of overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jiOZzvyJbsN"
      },
      "source": [
        "## Validate the model and comment the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khiB2wNSW-xd"
      },
      "source": [
        "### Performance metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LJcYAwxKjns"
      },
      "source": [
        "####Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0Z8KUa0rdK4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8a465a48-6a24-4bae-c8f3-20911ac250bb"
      },
      "source": [
        "score_opt = best_model.model.evaluate(X_train, Y_train, batch_size=128, verbose=0)\n",
        "print(\"Training loss: \", score_opt[0])\n",
        "print(\"Training accuracy: \", score_opt[1])"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  0.005156494677066803\n",
            "Training accuracy:  0.9986851811408997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6R4FNjsrrdLI",
        "outputId": "c0c642d6-150b-4c21-d43b-20297c19ea0e"
      },
      "source": [
        "predictions_opt = best_model.model.predict(X_train)\n",
        "y_classes_opt = np.round(predictions_opt).astype(np.int8)\n",
        "print(classification_report(y_classes_opt, Y_train, digits=5))"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99981   1.00000   0.99991      5347\n",
            "           1    0.99918   0.99852   0.99885      6075\n",
            "           2    0.99925   0.99963   0.99944      5335\n",
            "           3    0.99819   0.99964   0.99891      5524\n",
            "           4    0.99753   0.99829   0.99791      5253\n",
            "           5    0.99856   0.99877   0.99867      4877\n",
            "           6    1.00000   0.99888   0.99944      5341\n",
            "           7    0.99876   0.99806   0.99841      5672\n",
            "           8    0.99735   0.99943   0.99839      5263\n",
            "           9    0.99736   0.99623   0.99679      5306\n",
            "\n",
            "   micro avg    0.99861   0.99874   0.99868     53993\n",
            "   macro avg    0.99860   0.99874   0.99867     53993\n",
            "weighted avg    0.99861   0.99874   0.99868     53993\n",
            " samples avg    0.99861   0.99861   0.99861     53993\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhwLrp8NKwmz"
      },
      "source": [
        "####Validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WFSOK-ywOJXV",
        "outputId": "39baaccf-b6e5-4899-ea45-7535c3924d21"
      },
      "source": [
        "score_opt = best_model.model.evaluate(X_val, Y_val, batch_size=128, verbose=0)\n",
        "print(\"Validation loss: \", score_opt[0])\n",
        "print(\"Validation accuracy: \", score_opt[1])"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss:  0.031220274046063423\n",
            "Validation accuracy:  0.9915000200271606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nclsW3b-Kwm0",
        "outputId": "917017c1-3768-4015-80a1-87786d920514"
      },
      "source": [
        "predictions_opt = best_model.model.predict(X_val)\n",
        "y_classes_opt = np.round(predictions_opt).astype(np.int8)\n",
        "print(classification_report(y_classes_opt, Y_val, digits=5))"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99652   0.99307   0.99479       577\n",
            "           1    0.99702   0.98964   0.99332       676\n",
            "           2    0.98551   0.99190   0.98869       617\n",
            "           3    0.98831   0.99329   0.99079       596\n",
            "           4    0.99316   0.99147   0.99231       586\n",
            "           5    0.99448   0.98901   0.99174       546\n",
            "           6    0.99485   0.99828   0.99656       581\n",
            "           7    0.98827   0.98827   0.98827       597\n",
            "           8    0.98960   0.99304   0.99132       575\n",
            "           9    0.98767   0.98920   0.98843       648\n",
            "\n",
            "   micro avg    0.99150   0.99167   0.99158      5999\n",
            "   macro avg    0.99154   0.99172   0.99162      5999\n",
            "weighted avg    0.99151   0.99167   0.99158      5999\n",
            " samples avg    0.99150   0.99150   0.99150      5999\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxl6xSrwKxE3"
      },
      "source": [
        "####Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hVZJbfbwOM_F",
        "outputId": "da72cf4e-12cc-4d0b-f027-d03e738718bb"
      },
      "source": [
        "score_opt = best_model.model.evaluate(X_test, Y_test, batch_size=128, verbose=0)\n",
        "print(\"Test loss: \", score_opt[0])\n",
        "print(\"Test accuracy: \", score_opt[1])"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss:  0.02680101990699768\n",
            "Test accuracy:  0.9923999905586243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LtUY_t9FKxE3",
        "outputId": "eaca4ae1-2f7e-4efb-9ed6-5383c9001d6e"
      },
      "source": [
        "predictions_opt = best_model.model.predict(X_test)\n",
        "y_classes_opt = np.round(predictions_opt).astype(np.int8)\n",
        "print(classification_report(y_classes_opt, Y_test, digits=5))"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99286   0.99591   0.99438       977\n",
            "           1    0.99736   0.99211   0.99473      1141\n",
            "           2    0.98837   0.98933   0.98885      1031\n",
            "           3    0.99505   0.99702   0.99604      1008\n",
            "           4    0.99084   0.99591   0.99336       977\n",
            "           5    0.99552   0.99329   0.99440       894\n",
            "           6    0.98852   0.99266   0.99059       954\n",
            "           7    0.98930   0.98930   0.98930      1028\n",
            "           8    0.99076   0.99178   0.99127       973\n",
            "           9    0.98910   0.99106   0.99008      1007\n",
            "\n",
            "   micro avg    0.99180   0.99279   0.99230      9990\n",
            "   macro avg    0.99177   0.99284   0.99230      9990\n",
            "weighted avg    0.99181   0.99279   0.99230      9990\n",
            " samples avg    0.99180   0.99180   0.99180      9990\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUWQkg4iKwm0"
      },
      "source": [
        "#### Comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THT41IkNKwm0"
      },
      "source": [
        "As we can see, the performances are very good both in training and in validation or test sets. In fact we have for the training set an accuracy of 99.87%, and an accuracy of 99.15% and 99.24% respectively for. The model, despite having a slight overfitting on the training set, seems to have a good generalization capacity.\n",
        "\n",
        "For f1-score, since the classes are fairly balanced, both weighted avg and micro avg are a good general measure metric. Since we have f1-score results similar to those of accuracy, we can make the same conclusions."
      ]
    }
  ]
}